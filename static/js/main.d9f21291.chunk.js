(this["webpackJsonpreact-mrt"]=this["webpackJsonpreact-mrt"]||[]).push([[0],{147:function(e){e.exports=JSON.parse('{"root":{"paper_id":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","paper_title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding","paper_year":2018,"paper_venue":"NAACL-HLT","paper_citations":997,"paper_abstract":"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. \\nBERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)."},"branches":[[[{"paper_id":"38211dc39e41273c0007889202c69f841e02248a","paper_title":"ImageNet: A large-scale hierarchical image database","paper_year":2009,"paper_venue":"2009 IEEE Conference on Computer Vision and Pattern Recognition","paper_citations":999,"paper_abstract":"The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called \u201cImageNet\u201d, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond."},{"paper_id":"081651b38ff7533550a3adfc1c00da333a8fe86c","paper_title":"How transferable are features in deep neural networks?","paper_year":2014,"paper_venue":"NIPS","paper_citations":997,"paper_abstract":"Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Transferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difficulties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A final surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset."},{"paper_id":"0e6824e137847be0599bb0032e37042ed2ef5045","paper_title":"Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books","paper_year":2015,"paper_venue":"2015 IEEE International Conference on Computer Vision (ICCV)","paper_citations":287,"paper_abstract":"Books are a rich source of both fine-grained information, how a character, an object or a scene looks like, as well as high-level semantics, what someone is thinking, feeling and how these states evolve through a story. This paper aims to align books to their movie releases in order to provide rich descriptive explanations for visual content that go semantically far beyond the captions available in the current datasets. To align movies and books we propose a neural sentence embedding that is trained in an unsupervised way from a large corpus of books, as well as a video-text neural embedding for computing similarities between movie clips and sentences in the book. We propose a context-aware CNN to combine information from multiple sources. We demonstrate good quantitative performance for movie/book alignment and show several qualitative examples that showcase the diversity of tasks our model can be used for."},{"paper_id":"af5c4b80fbf847f69a202ba5a780a3dd18c1a027","paper_title":"SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference","paper_year":2018,"paper_venue":"EMNLP","paper_citations":64,"paper_abstract":"Given a partial description like \\"she opened the hood of the car,\\" humans can reason about the situation and anticipate what might come next (\\"then, she examined the engine\\"). In this paper, we introduce the task of grounded commonsense inference, unifying natural language inference and commonsense reasoning. \\nWe present SWAG, a new dataset with 113k multiple choice questions about a rich spectrum of grounded situations. To address the recurring challenges of the annotation artifacts and human biases found in many existing datasets, we propose Adversarial Filtering (AF), a novel procedure that constructs a de-biased dataset by iteratively training an ensemble of stylistic classifiers, and using them to filter the data. To account for the aggressive adversarial filtering, we use state-of-the-art language models to massively oversample a diverse set of potential counterfactuals. Empirical results demonstrate that while humans can solve the resulting inference problems with high accuracy (88%), various competitive models struggle on our task. We provide comprehensive analysis that indicates significant opportunities for future research."}],[{"paper_id":"069c40a8ca5305c9a0734c1f6134eb19a678f4ab","paper_title":"LabelMe: A Database and Web-Based Tool for Image Annotation","paper_year":2005,"paper_venue":"International Journal of Computer Vision","paper_citations":999,"paper_abstract":"Abstract\\nWe seek to build a large collection of images with ground truth labels to be used for object detection and recognition research. Such data is useful for supervised learning and quantitative evaluation. To achieve this, we developed a web-based tool that allows easy image annotation and instant sharing of such annotations. Using this annotation tool, we have collected a large dataset that spans many object categories, often containing multiple instances over a wide variety of images. We quantify the contents of the dataset and compare against existing state of the art datasets used for object recognition and detection. Also, we show how to extend the dataset to automatically enhance object labels with WordNet, discover object parts, recover a depth ordering of objects in a scene, and increase the number of labels using minimal user supervision and images from the web.\\n"},{"paper_id":"cbba352a37426a21b020d1ba8f61e5bca9ca20ae","paper_title":"Fully convolutional networks for semantic segmentation","paper_year":2015,"paper_venue":"CVPR","paper_citations":999,"paper_abstract":"Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build \u201cfully convolutional\u201d networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet [20], the VGG net [31], and GoogLeNet [32]) into fully convolutional networks and transfer their learned representations by fine-tuning [3] to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20% relative improvement to 62.2% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one fifth of a second for a typical image."},{"paper_id":"4b53c6b0193935e710e15a0e1ec3f9f25502e450","paper_title":"Xception: Deep Learning with Depthwise Separable Convolutions","paper_year":2016,"paper_venue":"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","paper_citations":999,"paper_abstract":"We present an interpretation of Inception modules in convolutional neural networks as being an intermediate step in-between regular convolution and the depthwise separable convolution operation (a depthwise convolution followed by a pointwise convolution). In this light, a depthwise separable convolution can be understood as an Inception module with a maximally large number of towers. This observation leads us to propose a novel deep convolutional neural network architecture inspired by Inception, where Inception modules have been replaced with depthwise separable convolutions. We show that this architecture, dubbed Xception, slightly outperforms Inception V3 on the ImageNet dataset (which Inception V3 was designed for), and significantly outperforms Inception V3 on a larger image classification dataset comprising 350 million images and 17,000 classes. Since the Xception architecture has the same number of parameters as Inception V3, the performance gains are not due to increased capacity but rather to a more efficient use of model parameters."},{"paper_id":"188770d6018a9596a08230d1f8404a5c4c6ee108","paper_title":"PRINCIPLES OF CATEGORIZATION","paper_year":1988,"paper_venue":"","paper_citations":999,"paper_abstract":"On those remote pages itis written that animals are divided into (a) those that belong tothe Emperor, (b)embalmed ones, (c) those that are trained, (d) suckling pigs, (e) mermaids, (f) fabulous ones, (g) stray dogs, (h) those that are included in this classification, (i) those that tremble as if they were mad, (j) innumerable ones, (k) those drawn with a very fine camel\x92s hair brush, (1) others, (m) those that have just broken a flower vase, (n) those that resemble f ies from"},{"paper_id":"14318685b5959b51d0f1e3db34643eb2855dc6d9","paper_title":"Going deeper with convolutions","paper_year":2014,"paper_venue":"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","paper_citations":999,"paper_abstract":"We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection."},{"paper_id":"54d2b5c64a67f65c5dd812b89e07973f97699552","paper_title":"80 Million Tiny Images: A Large Data Set for Nonparametric Object and Scene Recognition","paper_year":2008,"paper_venue":"IEEE Transactions on Pattern Analysis and Machine Intelligence","paper_citations":999,"paper_abstract":"With the advent of the Internet, billions of images are now freely available online and constitute a dense sampling of the visual world. Using a variety of non-parametric methods, we explore this world with the aid of a large dataset of 79,302,017 images collected from the Internet. Motivated by psychophysical results showing the remarkable tolerance of the human visual system to degradations in image resolution, the images in the dataset are stored as 32 x 32 color images. Each image is loosely labeled with one of the 75,062 non-abstract nouns in English, as listed in the Wordnet lexical database. Hence the image database gives a comprehensive coverage of all object categories and scenes. The semantic information from Wordnet can be used in conjunction with nearest-neighbor methods to perform object classification over a range of semantic levels minimizing the effects of labeling noise. For certain classes that are particularly prevalent in the dataset, such as people, we are able to demonstrate a recognition performance comparable to class-specific Viola-Jones style detectors."},{"paper_id":"b391878646123f5490ef2e2103de09a0947e4dc9","paper_title":"Scalable Recognition with a Vocabulary Tree","paper_year":2006,"paper_venue":"2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR\'06)","paper_citations":999,"paper_abstract":"A recognition scheme that scales efficiently to a large number of objects is presented. The efficiency and quality is exhibited in a live demonstration that recognizes CD-covers from a database of 40000 images of popular music CD\u2019s. The scheme builds upon popular techniques of indexing descriptors extracted from local regions, and is robust to background clutter and occlusion. The local region descriptors are hierarchically quantized in a vocabulary tree. The vocabulary tree allows a larger and more discriminatory vocabulary to be used efficiently, which we show experimentally leads to a dramatic improvement in retrieval quality. The most significant property of the scheme is that the tree directly defines the quantization. The quantization and the indexing are therefore fully integrated, essentially being one and the same. The recognition quality is evaluated through retrieval on a database with ground truth, showing the power of the vocabulary tree approach, going as high as 1 million images."},{"paper_id":"127316fbe268c78c519ceb23d41100e86639418a","paper_title":"CNN Features Off-the-Shelf: An Astounding Baseline for Recognition","paper_year":2014,"paper_venue":"2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops","paper_citations":999,"paper_abstract":"Recent results indicate that the generic descriptors extracted from the convolutional neural networks are very powerful. This paper adds to the mounting evidence that this is indeed the case. We report on a series of experiments conducted for different recognition tasks using the publicly available code and model of the OverFeat network which was trained to perform object classification on ILSVRC13. We use features extracted from the OverFeat network as a generic image representation to tackle the diverse range of recognition tasks of object image classification, scene recognition, fine grained recognition, attribute detection and image retrieval applied to a diverse set of datasets. We selected these tasks and datasets as they gradually move further away from the original task and data the OverFeat network was trained to solve. Astonishingly, we report consistent superior results compared to the highly tuned state-of-the-art systems in all the visual classification tasks on various datasets. For instance retrieval it consistently outperforms low memory footprint methods except for sculptures dataset. The results are achieved using a linear SVM classifier (or L2 distance in case of retrieval) applied to a feature representation of size 4096 extracted from a layer in the net. The representations are further modified using simple augmentation techniques e.g. jittering. The results strongly suggest that features obtained from deep learning with convolutional nets should be the primary candidate in most visual recognition tasks."},{"paper_id":"370b5757a5379b15e30d619e4d3fb9e8e13f3256","paper_title":"Labeled Faces in the Wild: A Database forStudying Face Recognition in Unconstrained Environments","paper_year":2008,"paper_venue":"","paper_citations":999,"paper_abstract":"Most face databases have been created under controlled conditions to facilitate the study of specific parameters on the face recognition problem. These parameters include such variables as position, pose, lighting, background, camera quality, and gender. While there are many applications for face recognition technology in which one can control the parameters of image acquisition, there are also many applications in which the practitioner has little or no control over such parameters. This database, Labeled Faces in the Wild, is provided as an aid in studying the latter, unconstrained, recognition problem. The database contains labeled face photographs spanning the range of conditions typically encountered in everyday life. The database exhibits \u201cnatural\u201d variability in factors such as pose, lighting, race, accessories, occlusions, and background. In addition to describing the details of the database, we provide specific experimental paradigms for which the database is suitable. This is done in an effort to make research performed with the database as consistent and comparable as possible. We provide baseline results, including results of a state of the art face recognition system combined with a face alignment system. To facilitate experimentation on the database, we provide several parallel databases, including an aligned version."},{"paper_id":"061356704ec86334dbbc073985375fe13cd39088","paper_title":"Very Deep Convolutional Networks for Large-Scale Image Recognition","paper_year":2014,"paper_venue":"ICLR","paper_citations":999,"paper_abstract":"Abstract: In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision."},{"paper_id":"5a5effa909cdeafaddbbb7855037e02f8e25d632","paper_title":"Caltech-256 Object Category Dataset","paper_year":2007,"paper_venue":"","paper_citations":999,"paper_abstract":"We introduce a challenging set of 256 object categories containing a total of 30607 images. The original Caltech-101 [1] was collected by choosing a set of object categories, downloading examples from Google Images and then manually screening out all images that did not fit the category. Caltech-256 is collected in a similar manner with several improvements: a) the number of categories is more than doubled, b) the minimum number of images in any category is increased from 31 to 80, c) artifacts due to image rotation are avoided and d) a new and larger clutter category is introduced for testing background rejection. We suggest several testing paradigms to measure classification performance, then benchmark the dataset using two simple metrics as well as a state-of-the-art spatial pyramid matching [2] algorithm. Finally we use the clutter category to train an interest detector which rejects uninformative background regions."}]],[[{"paper_id":"f04df4e20a18358ea2f689b4c129781628ef7fc1","paper_title":"A large annotated corpus for learning natural language inference","paper_year":2015,"paper_venue":"EMNLP","paper_citations":808,"paper_abstract":"Understanding entailment and contradiction is fundamental to understanding natural language, and inference about entailment and contradiction is a valuable testing ground for the development of semantic representations. However, machine learning research in this area has been dramatically limited by the lack of large-scale resources. To address this, we introduce the Stanford Natural Language Inference corpus, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. At 570K pairs, it is two orders of magnitude larger than all other resources of its type. This increase in scale allows lexicalized classifiers to outperform some sophisticated existing entailment models, and it allows a neural network-based model to perform competitively on natural language inference benchmarks for the first time."},{"paper_id":"ee7b883e35d754ae4f71c21bb71f9f03e4ffbb2c","paper_title":"Supervised Learning of Universal Sentence Representations from Natural Language Inference Data","paper_year":2017,"paper_venue":"EMNLP","paper_citations":474,"paper_abstract":"Many modern NLP systems rely on word embeddings, previously trained in an unsupervised manner on large corpora, as base features. Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful. Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted. In this paper, we show how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks. Much like how computer vision uses ImageNet to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for transfer learning to other NLP tasks. Our encoder is publicly available."},{"paper_id":"2cd8e8f510c89c7c18268e8ad51c061e459ad321","paper_title":"A Decomposable Attention Model for Natural Language Inference","paper_year":2016,"paper_venue":"EMNLP","paper_citations":410,"paper_abstract":"We propose a simple neural architecture for natural language inference. Our approach uses attention to decompose the problem into subproblems that can be solved separately, thus making it trivially parallelizable. On the Stanford Natural Language Inference (SNLI) dataset, we obtain state-of-the-art results with almost an order of magnitude fewer parameters than previous work and without relying on any word-order information. Adding intra-sentence attention that takes a minimum amount of order into account yields further improvements."},{"paper_id":"5ded2b8c64491b4a67f6d39ce473d4b9347a672e","paper_title":"A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference","paper_year":2017,"paper_venue":"NAACL-HLT","paper_citations":314,"paper_abstract":"This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. In addition to being one of the largest corpora available for the task of NLI, at 433k examples, this corpus improves upon available resources in its coverage: it offers data from ten distinct genres of written and spoken English--making it possible to evaluate systems on nearly the full complexity of the language--and it offers an explicit setting for the evaluation of cross-genre domain adaptation."},{"paper_id":"475354f10798f110d34792b6d88f31d6d5cb099e","paper_title":"Automatically Constructing a Corpus of Sentential Paraphrases","paper_year":2005,"paper_venue":"IWP@IJCNLP","paper_citations":192,"paper_abstract":"An obstacle to research in automatic paraphrase identification and generation is the lack of large-scale, publiclyavailable labeled corpora of sentential paraphrases. This paper describes the creation of the recently-released Microsoft Research Paraphrase Corpus, which contains 5801 sentence pairs, each hand-labeled with a binary judgment as to whether the pair constitutes a paraphrase. The corpus was created using heuristic extraction techniques in conjunction with an SVM-based classifier to select likely sentence-level paraphrases from a large corpus of topicclustered news data. These pairs were then submitted to human judges, who confirmed that 67% were in fact semantically equivalent. In addition to describing the corpus itself, we explore a number of issues that arose in defining guidelines for the human raters."},{"paper_id":"93b8da28d006415866bf48f9a6e06b5242129195","paper_title":"GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding","paper_year":2018,"paper_venue":"ICLR","paper_citations":159,"paper_abstract":"For natural language understanding (NLU) technology to be maximally useful, both practically and as a scientific object of study, it must be general: it must be able to process language in a way that is not exclusively tailored to any one specific task or dataset. In pursuit of this objective, we introduce the General Language Understanding Evaluation benchmark (GLUE), a tool for evaluating and analyzing the performance of models across a diverse range of existing NLU tasks. GLUE is model-agnostic, but it incentivizes sharing knowledge across tasks because certain tasks have very limited training data. We further provide a hand-crafted diagnostic test suite that enables detailed linguistic analysis of NLU models. We evaluate baselines based on current methods for multi-task and transfer learning and find that they do not immediately give substantial improvements over the aggregate performance of training a separate model per task, indicating room for improvement in developing general and robust NLU systems."},{"paper_id":"a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096","paper_title":"SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation","paper_year":2017,"paper_venue":"SemEval@ACL","paper_citations":156,"paper_abstract":"Semantic Textual Similarity (STS) measures the meaning similarity of sentences. Applications include machine translation (MT), summarization, generation, question answering (QA), short answer grading, semantic search, dialog and conversational systems. The STS shared task is a venue for assessing the current state-of-the-art. The 2017 task focuses on multilingual and cross-lingual pairs with one sub-track exploring MT quality estimation (MTQE) data. The task obtained strong participation from 31 teams, with 17 participating in all language tracks. We summarize performance and review a selection of well performing methods. Analysis highlights common errors, providing insight into the limitations of existing models. To support ongoing work on semantic representations, the STS Benchmark is introduced as a new shared training and evaluation set carefully selected from the corpus of English STS shared task data (2012-2017)."}],[{"paper_id":"e85a71c8cae795a1b2052a697d5e8182cc8c0655","paper_title":"The Stanford CoreNLP Natural Language Processing Toolkit","paper_year":2014,"paper_venue":"ACL","paper_citations":999,"paper_abstract":"We describe the design and use of the Stanford CoreNLP toolkit, an extensible pipeline that provides core natural language analysis. This toolkit is quite widely used, both in the research NLP community and also among commercial and government users of open source NLP technology. We suggest that this follows from a simple, approachable design, straightforward interfaces, the inclusion of robust and good quality analysis components, and not requiring use of a large amount of associated baggage."},{"paper_id":"01a660ec8aa995a88a00bfb41cb86c022047a9db","paper_title":"NLTK: The Natural Language Toolkit","paper_year":2002,"paper_venue":"ACL","paper_citations":999,"paper_abstract":"NLTK, the Natural Language Toolkit, is a suite of open source program modules, tutorials and problem sets, providing ready-to-use computational linguistics courseware. NLTK covers symbolic and statistical natural language processing, and is interfaced to annotated corpora. Students augment and replace existing components, learn structured programming by example, and manipulate sophisticated models from the outset."}]],[[{"paper_id":"9fa8d73e572c3ca824a04a5f551b602a17831bc5","paper_title":"Domain Adaptation with Structural Correspondence Learning","paper_year":2006,"paper_venue":"EMNLP","paper_citations":925,"paper_abstract":"Discriminative learning methods are widely used in natural language processing. These methods work best when their training and test data are drawn from the same distribution. For many NLP tasks, however, we are confronted with new domains in which labeled data is scarce or non-existent. In such cases, we seek to adapt existing models from a resource-rich source domain to a resource-poor target domain. We introduce structural correspondence learning to automatically induce correspondences among features from different domains. We test our technique on part of speech tagging and show performance gains for varying amounts of source and target training data, as well as improvements in target domain parsing accuracy using our improved tagger."},{"paper_id":"2c5135a0531bc5ad7dd890f018e67a40529f5bcb","paper_title":"A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data","paper_year":2005,"paper_venue":"J. Mach. Learn. Res.","paper_citations":822,"paper_abstract":"One of the most important issues in machine learning is whether one can improve the performance of a supervised learning algorithm by including unlabeled data. Methods that use both labeled and unlabeled data are generally referred to as semi-supervised learning. Although a number of such methods are proposed, at the current stage, we still don\'t have a complete understanding of their effectiveness. This paper investigates a closely related problem, which leads to a novel approach to semi-supervised learning. Specifically we consider learning predictive structures on hypothesis spaces (that is, what kind of classifiers have good predictive power) from multiple learning tasks. We present a general framework in which the structural learning problem can be formulated and analyzed theoretically, and relate it to learning with unlabeled data. Under this framework, algorithms for structural learning will be proposed, and computational issues will be investigated. Experiments will be given to demonstrate the effectiveness of the proposed algorithms in the semi-supervised learning setting."},{"paper_id":"10f97f1fb4f5c2c8e6c44d4a33da46d331dd4aeb","paper_title":"Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition","paper_year":2003,"paper_venue":"CoNLL","paper_citations":789,"paper_abstract":"We describe the CoNLL-2003 shared task: language-independent named entity recognition. We give background information on the data sets (English and German) and the evaluation method, present a general overview of the systems that have taken part in the task and discuss their performance."},{"paper_id":"128cb6b891aee1b5df099acb48e2efecfcff689f","paper_title":"The Winograd Schema Challenge","paper_year":2011,"paper_venue":"AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning","paper_citations":198,"paper_abstract":"In this paper, we present an alternative to the Turing Test that has some conceptual and practical advantages. Like the original, it involves responding to typed English sentences, and English-speaking adults will have no difficulty with it. Unlike the original, the subject is not required to engage in a conversation and fool an interrogator into believing she is dealing with a person. Moreover, the test is arranged in such a way that having full access to a large corpus of English text might not help much. Finally, the interrogator or a third party will be able to decide unambiguously after a few minutes whether or not a subject has passed the test."},{"paper_id":"0bb4cadc80c0afaf29c57518dc9c06f8fcfa5f38","paper_title":"Semi-supervised sequence tagging with bidirectional language models","paper_year":2017,"paper_venue":"ACL","paper_citations":145,"paper_abstract":"Pre-trained word embeddings learned from unlabeled text have become a standard component of neural network architectures for NLP tasks. However, in most cases, the recurrent network that operates on word-level representations to produce context sensitive representations is trained on relatively little labeled data. In this paper, we demonstrate a general semi-supervised approach for adding pre- trained context embeddings from bidirectional language models to NLP systems and apply it to sequence labeling tasks. We evaluate our model on two standard datasets for named entity recognition (NER) and chunking, and in both cases achieve state of the art results, surpassing previous systems that use other forms of transfer or joint learning with additional labeled data and task specific gazetteers."},{"paper_id":"421fc2556836a6b441de806d7b393a35b6eaea58","paper_title":"Contextual String Embeddings for Sequence Labeling","paper_year":2018,"paper_venue":"COLING","paper_citations":85,"paper_abstract":"Recent advances in language modeling using recurrent neural networks have made it viable to model language as distributions over characters. By learning to predict the next character on the basis of previous characters, such models have been shown to automatically internalize linguistic concepts such as words, sentences, subclauses and even sentiment. In this paper, we propose to leverage the internal states of a trained character language model to produce a novel type of word embedding which we refer to as contextual string embeddings. Our proposed embeddings have the distinct properties that they (a) are trained without any explicit notion of words and thus fundamentally model words as sequences of characters, and (b) are contextualized by their surrounding text, meaning that the same word will have different embeddings depending on its contextual use. We conduct a comparative evaluation against previous embeddings and find that our embeddings are highly useful for downstream tasks: across four classic sequence labeling tasks we consistently outperform the previous state-of-the-art. In particular, we significantly outperform previous work on English and German named entity recognition (NER), allowing us to report new state-of-the-art F1-scores on the CONLL03 shared task. We release all code and pre-trained language models in a simple-to-use framework to the research community, to enable reproduction of these experiments and application of our proposed embeddings to other tasks: https://github.com/zalandoresearch/flair"},{"paper_id":"cb0f3ee1e98faf92429d601cdcd76c69c1e484eb","paper_title":"Neural Network Acceptability Judgments","paper_year":2018,"paper_venue":"ArXiv","paper_citations":34,"paper_abstract":"In this work, we explore the ability of artificial neural networks to judge the grammatical acceptability of a sentence. Machine learning research of this kind is well placed to answer important open questions about the role of prior linguistic bias in language acquisition by providing a test for the Poverty of the Stimulus Argument. In service of this goal, we introduce the Corpus of Linguistic Acceptability (CoLA), a set of 10,657 English sentences labeled as grammatical or ungrammatical by expert linguists. We train several recurrent neural networks to do binary acceptability classification. These models set a baseline for the task. Error-analysis testing the models on specific grammatical phenomena reveals that they learn some systematic grammatical generalizations like subject-verb-object word order without any grammatical supervision. We find that neural sequence models show promise on the acceptability classification task. However, human-like performance across a wide range of grammatical constructions remains far off."},{"paper_id":"0c47cad9729c38d9db1f75491b1ee4bd883a5d4e","paper_title":"Semi-Supervised Sequence Modeling with Cross-View Training","paper_year":2018,"paper_venue":"EMNLP","paper_citations":32,"paper_abstract":"Unsupervised representation learning algorithms such as word2vec and ELMo improve the accuracy of many supervised NLP models, mainly because they can take advantage of large amounts of unlabeled text. However, the supervised models only learn from task-specific labeled data during the main training phase. We therefore propose Cross-View Training (CVT), a semi-supervised learning algorithm that improves the representations of a Bi-LSTM sentence encoder using a mix of labeled and unlabeled data. On labeled examples, standard supervised learning is used. On unlabeled examples, CVT teaches auxiliary prediction modules that see restricted views of the input (e.g., only part of a sentence) to match the predictions of the full model seeing the whole input. Since the auxiliary modules and the full model share intermediate representations, this in turn improves the full model. Moreover, we show that CVT is particularly effective when combined with multi-task learning. We evaluate CVT on five sequence tagging tasks, machine translation, and dependency parsing, achieving state-of-the-art results."}],[{"paper_id":"d895647b4a80861703851ef55930a2627fe19492","paper_title":"Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification","paper_year":2007,"paper_venue":"ACL","paper_citations":999,"paper_abstract":"Automatic sentiment classification has been extensively studied and applied in recent years. However, sentiment is expressed differently in different domains, and annotating corpora for every possible domain of interest is impractical. We investigate domain adaptation for sentiment classifiers, focusing on online reviews for different types of products. First, we extend to sentiment classification the recently-proposed structural correspondence learning (SCL) algorithm, reducing the relative error due to adaptation between domains by an average of 30% over the original SCL algorithm and 46% over a supervised baseline. Second, we identify a measure of domain similarity that correlates well with the potential for adaptation of a classifier from one domain to another. This measure could for instance be used to select a small set of domains to annotate whose trained classifiers would transfer well to many other domains."},{"paper_id":"284b18d7196f608448ca3d9496bf220b1dfffcf5","paper_title":"Deep Boltzmann Machines","paper_year":2009,"paper_venue":"AISTATS","paper_citations":999,"paper_abstract":"We present a new learning algorithm for Boltzmann machines that contain many layers of hidden variables. Data-dependent expectations are estimated using a variational approximation that tends to focus on a single mode, and dataindependent expectations are approximated using persistent Markov chains. The use of two quite different techniques for estimating the two types of expectation that enter into the gradient of the log-likelihood makes it practical to learn Boltzmann machines with multiple hidden layers and millions of parameters. The learning can be made more efficient by using a layer-by-layer \u201cpre-training\u201d phase that allows variational inference to be initialized with a single bottomup pass. We present results on the MNIST and NORB datasets showing that deep Boltzmann machines learn good generative models and perform well on handwritten digit and visual object recognition tasks."},{"paper_id":"2538e3eb24d26f31482c479d95d2e26c0e79b990","paper_title":"Natural Language Processing (almost) from Scratch","paper_year":2011,"paper_venue":"J. Mach. Learn. Res.","paper_citations":999,"paper_abstract":"We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements."},{"paper_id":"15b2c44b3868a1055850846161aaca59083e0529","paper_title":"Learning with Local and Global Consistency","paper_year":2003,"paper_venue":"NIPS","paper_citations":999,"paper_abstract":"We consider the general problem of learning from labeled and unlabeled data, which is often called semi-supervised learning or transductive inference. A principled approach to semi-supervised learning is to design a classifying function which is sufficiently smooth with respect to the intrinsic structure collectively revealed by known labeled and unlabeled points. We present a simple algorithm to obtain such a smooth solution. Our method yields encouraging experimental results on a number of classification problems and demonstrates effective use of unlabeled data."},{"paper_id":"17accbdd4aa3f9fad6af322bc3d7f4d5b648d9cd","paper_title":"Transductive Inference for Text Classification using Support Vector Machines","paper_year":1999,"paper_venue":"ICML","paper_citations":999,"paper_abstract":"This paper introduces Transductive Support Vector Machines (TSVMs) for text classi cation. While regular Support Vector Machines (SVMs) try to induce a general decision function for a learning task, Transductive Support Vector Machines take into account a particular test set and try to minimize misclassi cations of just those particular examples. The paper presents an analysis of why TSVMs are well suited for text classi cation. These theoretical ndings are supported by experiments on three test collections. The experiments show substantial improvements over inductive methods, especially for small training sets, cutting the number of labeled training examples down to a twentieth on some tasks. This work also proposes an algorithm for training TSVMs e ciently, handling 10,000 examples and more."},{"paper_id":"0c04909ed933469246defcf9aca2b71ae8e3f623","paper_title":"Information Retrieval","paper_year":1979,"paper_venue":"Encyclopedia of GIS","paper_citations":999,"paper_abstract":"The major change in the second edition of this book is the addition of a new chapter on probabilistic retrieval. This chapter has been included because I think this is one of the most interesting and active areas of research in information retrieval. There are still many problems to be solved so I hope that this particular chapter will be of some help to those who want to advance the state of knowledge in this area. All the other chapters have been updated by including some of the more recent work on the topics covered. In preparing this new edition I have benefited from discussions with Bruce Croft, The material of this book is aimed at advanced undergraduate information (or computer) science students, postgraduate library science students, and research workers in the field of IR. Some of the chapters, particularly Chapter 6 * , make simple use of a little advanced mathematics. However, the necessary mathematical tools can be easily mastered from numerous mathematical texts that now exist and, in any case, references have been given where the mathematics occur. I had to face the problem of balancing clarity of exposition with density of references. I was tempted to give large numbers of references but was afraid they would have destroyed the continuity of the text. I have tried to steer a middle course and not compete with the Annual Review of Information Science and Technology. Normally one is encouraged to cite only works that have been published in some readily accessible form, such as a book or periodical. Unfortunately, much of the interesting work in IR is contained in technical reports and Ph.D. theses. For example, most the work done on the SMART system at Cornell is available only in reports. Luckily many of these are now available through the National Technical Information Service (U.S.) and University Microfilms (U.K.). I have not avoided using these sources although if the same material is accessible more readily in some other form I have given it preference. I should like to acknowledge my considerable debt to many people and institutions that have helped me. Let me say first that they are responsible for many of the ideas in this book but that only I wish to be held responsible. My greatest debt is to Karen Sparck Jones who taught me to research information retrieval as an experimental science. Nick Jardine and Robin \u2026"},{"paper_id":"eb42a490cf4f186d3383c92963817d100afd81e2","paper_title":"Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network","paper_year":2003,"paper_venue":"HLT-NAACL","paper_citations":999,"paper_abstract":"We present a new part-of-speech tagger that demonstrates the following ideas: (i) explicit use of both preceding and following tag contexts via a dependency network representation, (ii) broad use of lexical features, including jointly conditioning on multiple consecutive words, (iii) effective use of priors in conditional loglinear models, and (iv) fine-grained modeling of unknown word features. Using these ideas together, the resulting tagger gives a 97.24% accuracy on the Penn Treebank WSJ, an error reduction of 4.4% on the best previous single automatically learned tagging result."},{"paper_id":"10eb7bfa7687f498268bdf74b2f60020a151bdc6","paper_title":"Visualizing Data using t-SNE","paper_year":2008,"paper_venue":"","paper_citations":999,"paper_abstract":"We present a new technique called \u201ct-SNE\u201d that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images of objects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large datasets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence the way in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of datasets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualizations produced by t-SNE are significantly better than those produced by the other techniques on almost all of the datasets."},{"paper_id":"8213dbed4db44e113af3ed17d6dad57471a0c048","paper_title":"The Nature of Statistical Learning Theory","paper_year":1995,"paper_venue":"Statistics for Engineering and Information Science","paper_citations":999,"paper_abstract":"Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?."},{"paper_id":"0c7f52c753a65ceaf3755e20b906ffd0c05c994a","paper_title":"Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data","paper_year":2001,"paper_venue":"ICML","paper_citations":999,"paper_abstract":"We present conditional random fields , a framework for building probabilistic models to segment and label sequence data. Conditional random fields offer several advantages over hidden Markov models and stochastic grammars for such tasks, including the ability to relax strong independence assumptions made in those models. Conditional random fields also avoid a fundamental limitation of maximum entropy Markov models (MEMMs) and other discriminative Markov models based on directed graphical models, which can be biased towards states with few successor states. We present iterative parameter estimation algorithms for conditional random fields and compare the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."},{"paper_id":"33ccb3e8634a93533c8920a0f820dc0c4bb5a986","paper_title":"ENGLISH VERB CLASSES AND ALTERNATIONS: A PRELIMINARY INVESTIGATION. Beth Levin. Chicago: The University of Chicago Press, 1993. Pp. xvii + 348. $45.00 cloth, $18.95 paper.","paper_year":1995,"paper_venue":"","paper_citations":999,"paper_abstract":""},{"paper_id":"45ee7447b9dd406496c4a5d9d8fb6556366a01c6","paper_title":"Weak Convergence and Empirical Processes","paper_year":1996,"paper_venue":"","paper_citations":999,"paper_abstract":""},{"paper_id":"f28cd8803a0d453d389cdc270923231cbf4ebafc","paper_title":"Computing Machinery and Intelligence","paper_year":1950,"paper_venue":"","paper_citations":999,"paper_abstract":"I propose to consider the question, \u201cCan machines think?\u201d\u2663 This should begin with definitions of the meaning of the terms \u201cmachine\u201d and \u201cthink\u201d. The definitions might be framed so as to reflect so far as possible the normal use of the words, but this attitude is dangerous. If the meaning of the words \u201cmachine\u201d and \u201cthink\u201d are to be found by examining how they are commonly used it is difficult to escape the conclusion that the meaning and the answer to the question, \u201cCan machines think?\u201d is to be sought in a statistical survey such as a Gallup poll."},{"paper_id":"b25663fa149be5286de193c13324098aedd7e2cc","paper_title":"Opinion Mining and Sentiment Analysis","paper_year":2007,"paper_venue":"Foundations and Trends in Information Retrieval","paper_citations":999,"paper_abstract":"An important part of our information-gathering behavior has always been to find out what other people think. With the growing availability and popularity of opinion-rich resources such as online review sites and personal blogs, new opportunities and challenges arise as people now can, and do, actively use information technologies to seek out and understand the opinions of others. The sudden eruption of activity in the area of opinion mining and sentiment analysis, which deals with the computational treatment of opinion, sentiment, and subjectivity in text, has thus occurred at least in part as a direct response to the surge of interest in new systems that deal directly with opinions as a first-class object. \\n \\nThis survey covers techniques and approaches that promise to directly enable opinion-oriented information-seeking systems. Our focus is on methods that seek to address the new challenges raised by sentiment-aware applications, as compared to those that are already present in more traditional fact-based analysis. We include material on summarization of evaluative text and on broader issues regarding privacy, manipulation, and economic impact that the development of opinion-oriented information-access services gives rise to. To facilitate future work, a discussion of available resources, benchmark datasets, and evaluation campaigns is also provided."},{"paper_id":"02485a373142312c354b79552b3d326913eaf86d","paper_title":"Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions","paper_year":2003,"paper_venue":"ICML","paper_citations":999,"paper_abstract":"Active and semi-supervised learning are important techniques when labeled data are scarce. We combine the two under a Gaussian random field model. Labeled and unlabeled data are represented as vertices in a weighted graph, with edge weights encoding the similarity between instances. The semi-supervised learning problem is then formulated in terms of a Gaussian random field on this graph, the mean of which is characterized in terms of harmonic functions. Active learning is performed on top of the semisupervised learning scheme by greedily selecting queries from the unlabeled data to minimize the estimated expected classification error (risk); in the case of Gaussian fields the risk is efficiently computed using matrix methods. We present experimental results on synthetic data, handwritten digit recognition, and text classification tasks. The active learning scheme requires a much smaller number of queries to achieve high accuracy compared with random query selection."},{"paper_id":"df01d2dede1a243b9b0eb26c27246bc13705d930","paper_title":"Exploiting Generative Models in Discriminative Classifiers","paper_year":1998,"paper_venue":"NIPS","paper_citations":999,"paper_abstract":"Generative probability models such as hidden Markov models provide a principled way of treating missing information and dealing with variable length sequences. On the other hand, discriminative methods such as support vector machines enable us to construct flexible decision boundaries and often result in classification performance superior to that of the model based approaches. An ideal classifier should combine these two complementary approaches. In this paper, we develop a natural way of achieving this combination by deriving kernel functions for use in discriminative methods such as support vector machines from generative probability models. We provide a theoretical justification for this combination as well as demonstrate a substantial improvement in the classification performance in the context of DNA and protein sequence analysis."}]],[[{"paper_id":"1510cf4b8abea80b9f352325ca4c132887de21a0","paper_title":"Distributed Representations of Sentences and Documents","paper_year":2014,"paper_venue":"ICML","paper_citations":999,"paper_abstract":"Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, \\"powerful,\\" \\"strong\\" and \\"Paris\\" are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks."},{"paper_id":"687bac2d3320083eb4530bf18bb8f8f721477600","paper_title":"Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank","paper_year":2013,"paper_venue":"EMNLP","paper_citations":999,"paper_abstract":"Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases."},{"paper_id":"1a07186bc10592f0330655519ad91652125cd907","paper_title":"A unified architecture for natural language processing: deep neural networks with multitask learning","paper_year":2008,"paper_venue":"ICML","paper_citations":999,"paper_abstract":"We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance."},{"paper_id":"f37e1b62a767a307c046404ca96bc140b3e68cb5","paper_title":"Glove: Global Vectors for Word Representation","paper_year":2014,"paper_venue":"EMNLP","paper_citations":999,"paper_abstract":"Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition."},{"paper_id":"87f40e6f3022adbc1f1905e3e506abad05a9964f","paper_title":"Distributed Representations of Words and Phrases and their Compositionality","paper_year":2013,"paper_venue":"NIPS","paper_citations":999,"paper_abstract":"The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \\"Canada\\" and \\"Air\\" cannot be easily combined to obtain \\"Air Canada\\". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible."},{"paper_id":"783480acff435bfbc15ffcdb4f15eccddaa0c810","paper_title":"Class-Based n-gram Models of Natural Language","paper_year":1992,"paper_venue":"Computational Linguistics","paper_citations":999,"paper_abstract":"We address the problem of predicting a word from previous words in a sample of text. In particular, we discuss n-gram models based on classes of words. We also discuss several statistical algorithms for assigning words to classes based on the frequency of their co-occurrence with other words. We find that we are able to extract classes that have the flavor of either syntactically based groupings or semantically based groupings, depending on the nature of the underlying statistics."},{"paper_id":"dac72f2c509aee67524d3321f77e97e8eff51de6","paper_title":"Word Representations: A Simple and General Method for Semi-Supervised Learning","paper_year":2010,"paper_venue":"ACL","paper_citations":999,"paper_abstract":"If we take an existing supervised NLP system, a simple and general way to improve accuracy is to use unsupervised word representations as extra word features. We evaluate Brown clusters, Collobert and Weston (2008) embeddings, and HLBL (Mnih & Hinton, 2009) embeddings of words on both NER and chunking. We use near state-of-the-art supervised baselines, and find that each of the three word representations improves the accuracy of these baselines. We find further improvements by combining different word representations. You can download our word features, for off-the-shelf use in existing NLP systems, as well as our code, here: http://metaoptimize.com/projects/wordreprs/"},{"paper_id":"1005645c05585c2042e3410daeed638b55e2474d","paper_title":"A Scalable Hierarchical Distributed Language Model","paper_year":2008,"paper_venue":"NIPS","paper_citations":591,"paper_abstract":"Neural probabilistic language models (NPLMs) have been shown to be competitive with and occasionally superior to the widely-used n-gram language models. The main drawback of NPLMs is their extremely long training and testing times. Morin and Bengio have proposed a hierarchical language model built around a binary tree of words, which was two orders of magnitude faster than the non-hierarchical model it was based on. However, it performed considerably worse than its non-hierarchical counterpart in spite of using a word tree created using expert knowledge. We introduce a fast hierarchical language model along with a simple feature-based algorithm for automatic construction of word trees from the data. We then show that the resulting models can outperform non-hierarchical neural models as well as the best n-gram models."},{"paper_id":"26e743d5bd465f49b9538deaf116c15e61b7951f","paper_title":"Learning Distributed Representations of Sentences from Unlabelled Data","paper_year":2016,"paper_venue":"HLT-NAACL","paper_citations":238,"paper_abstract":"Unsupervised methods for learning distributed representations of words are ubiquitous in today\'s NLP research, but far less is known about the best ways to learn distributed phrase or sentence representations from unlabelled data. This paper is a systematic comparison of models that learn such representations. We find that the optimal approach depends critically on the intended application. Deeper, more complex models are preferable for representations to be used in supervised systems, but shallow log-linear models work best for building representation spaces that can be decoded with simple spatial distance metrics. We also propose two new unsupervised representation-learning objectives designed to optimise the trade-off between training time, domain portability and performance."},{"paper_id":"59761abc736397539bdd01ad7f9d91c8607c0457","paper_title":"context2vec: Learning Generic Context Embedding with Bidirectional LSTM","paper_year":2016,"paper_venue":"CoNLL","paper_citations":124,"paper_abstract":"Context representations are central to various NLP tasks, such as word sense disambiguation, named entity recognition, coreference resolution, and many more. In this work we present a neural model for efficiently learning a generic context embedding function from large corpora, using bidirectional LSTM. With a very simple application of our context representations, we manage to surpass or nearly reach state-of-the-art results on sentence completion, lexical substitution and word sense disambiguation tasks, while substantially outperforming the popular context representation of averaged word embeddings. We release our code and pretrained models, suggesting they could be useful in a wide variety of NLP tasks."}],[{"paper_id":"d4e8bed3b50a035e1eabad614fe4218a34b3b178","paper_title":"An Empirical Study of Smoothing Techniques for Language Modeling","paper_year":1996,"paper_venue":"ACL","paper_citations":999,"paper_abstract":"We present an extensive empirical comparison of several smoothing techniques in the domain of language modeling, including those described by Jelinek and Mercer (1980), Katz (1987), and Church and Gale (1991). We investigate for the first time how factors such as training data size, corpus (e.g., Brown versus Wall Street Journal), and n-gram order (bigram versus trigram) affect the relative performance of these methods, which we measure through the cross-entropy of test data. In addition, we introduce two novel smoothing techniques, one a variation of Jelinek-Mercer smoothing and one a very simple linear interpolation technique, both of which outperform existing methods."},{"paper_id":"649d03490ef72c5274e3bccd03d7a299d2f8da91","paper_title":"Learning Word Vectors for Sentiment Analysis","paper_year":2011,"paper_venue":"ACL","paper_citations":999,"paper_abstract":"Unsupervised vector-based approaches to semantics can model rich lexical meanings, but they largely fail to capture sentiment information that is central to many word meanings and important for a wide range of NLP tasks. We present a model that uses a mix of unsupervised and supervised techniques to learn word vectors capturing semantic term--document information as well as rich sentiment content. The proposed model can leverage both continuous and multi-dimensional sentiment information as well as non-sentiment annotations. We instantiate the model to utilize the document-level sentiment polarity annotations present in many online documents (e.g. star ratings). We evaluate the model using small, widely used sentiment and subjectivity corpora and find it out-performs several previously introduced methods for sentiment classification. We also introduce a large dataset of movie reviews to serve as a more robust benchmark for work in this area."},{"paper_id":"83a6cacc126d85c45605797406262677c256a6af","paper_title":"Software Framework for Topic Modelling with Large Corpora","paper_year":2010,"paper_venue":"","paper_citations":999,"paper_abstract":"Large corpora are ubiquitous in today\'s world and memory\\nquickly becomes the limiting factor in practical applications\\nof the Vector Space Model (VSM). We identify gap in existing\\nVSM implementations, which is their scalability and ease of\\nuse. We describe a Natural Language Processing software\\nframework which is based on the idea of document streaming,\\ni.e. processing corpora document after document, in a memory\\nindependent fashion. In this framework, we implement several\\npopular algorithms for topical inference, including Latent\\nSemantic Analysis and Latent Dirichlet Allocation, in a way\\nthat makes them completely independent of the training corpus\\nsize. Particular emphasis is placed on straightforward and\\nintuitive framework design, so that modifications and\\nextensions of the methods and/or their application by\\ninterested practitioners are effortless. We demonstrate the\\nusefulness of our approach on a real-world scenario of\\ncomputing document similarities within an existing digital\\nlibrary DML-CZ."},{"paper_id":"b2986b25f50babd536dd0ecf2237d9eabf5843c2","paper_title":"THE POPULATION FREQUENCIES OF SPECIES AND THE ESTIMATION OF POPULATION PARAMETERS","paper_year":1953,"paper_venue":"","paper_citations":999,"paper_abstract":""},{"paper_id":"e5305866d701a2c102c5f81fbbf48bf6ac29f252","paper_title":"Indexing by Latent Semantic Analysis","paper_year":1990,"paper_venue":"","paper_citations":999,"paper_abstract":"A new method for automatic indexing and retrieval is described. The approach is to take advantage of implicit higher-order structure in the association of terms with documents (\u201csemantic structure\u201d) in order to improve the detection of relevant documents on the basis of terms found in queries. The particular technique used is singular-value decomposition, in which a large term by document matrix is decomposed into a set of ca. 100 orthogonal factors from which the original matrix can be approximated by linear combination. Documents are represented by ca. 100 item vectors of factor weights. Queries are represented as pseudo-document vectors formed from weighted combinations of terms, and documents with supra-threshold cosine values are returned. initial tests find this completely automatic method for retrieval to be promising."}]],[[{"paper_id":"843959ffdccf31c6694d135fad07425924f785b1","paper_title":"Extracting and composing robust features with denoising autoencoders","paper_year":2008,"paper_venue":"ICML","paper_citations":999,"paper_abstract":"Previous work has shown that the difficulties in learning deep generative or discriminative models can be overcome by an initial unsupervised learning step that maps inputs to useful intermediate representations. We introduce and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern. This approach can be used to train autoencoders, and these denoising autoencoders can be stacked to initialize deep architectures. The algorithm can be motivated from a manifold learning and information theoretic perspective or from a generative model perspective. Comparative experiments clearly show the surprising advantage of corrupting the input of autoencoders on a pattern classification benchmark suite."},{"paper_id":"3febb2bed8865945e7fddc99efd791887bb7e14f","paper_title":"Deep contextualized word representations","paper_year":2018,"paper_venue":"NAACL-HLT","paper_citations":999,"paper_abstract":"We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pretrained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pretrained network is crucial, allowing downstream models to mix different types of semi-supervision signals."},{"paper_id":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","paper_title":"Attention Is All You Need","paper_year":2017,"paper_venue":"NIPS","paper_citations":997,"paper_abstract":"The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms. We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1."},{"paper_id":"6e795c6e9916174ae12349f5dc3f516570c17ce8","paper_title":"Skip-Thought Vectors","paper_year":2015,"paper_venue":"NIPS","paper_citations":846,"paper_abstract":"We describe an approach for unsupervised learning of a generic, distributed sentence encoder. Using the continuity of text from books, we train an encoder-decoder model that tries to reconstruct the surrounding sentences of an encoded passage. Sentences that share semantic and syntactic properties are thus mapped to similar vector representations. We next introduce a simple vocabulary expansion method to encode words that were not seen as part of training, allowing us to expand our vocabulary to a million words. After training our model, we extract and evaluate our vectors with linear models on 8 tasks: semantic relatedness, paraphrase detection, image-sentence ranking, question-type classification and 4 benchmark sentiment and subjectivity datasets. The end result is an off-the-shelf encoder that can produce highly generic sentence representations that are robust and perform well in practice. We will make our encoder publicly available."},{"paper_id":"5d833331b0e22ff359db05c62a8bca18c4f04b68","paper_title":"One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling","paper_year":2013,"paper_venue":"INTERSPEECH","paper_citations":423,"paper_abstract":"We propose a new benchmark corpus to be used for measuring progress in statistical language modeling. With almost one billion words of training data, we hope this benchmark will be useful to quickly evaluate novel language modeling techniques, and to compare their contribution when combined with other advanced techniques. We show performance of several well-known types of language models, with the best results achieved with a recurrent neural network based language model. The baseline unpruned Kneser-Ney 5-gram model achieves perplexity 67.6; a combination of techniques leads to 35% reduction in perplexity, or 10% reduction in cross-entropy (bits), over that baseline. \\nThe benchmark is available as a code.google.com project; besides the scripts needed to rebuild the training/held-out data, it also makes available log-probability values for each word in each of ten held-out data sets, for each of the baseline n-gram models."},{"paper_id":"4aa9f5150b46320f534de4747a2dd0cd7f3fe292","paper_title":"Semi-supervised Sequence Learning","paper_year":2015,"paper_venue":"NIPS","paper_citations":364,"paper_abstract":"We present two approaches that use unlabeled data to improve sequence learning with recurrent networks. The first approach is to predict what comes next in a sequence, which is a conventional language model in natural language processing. The second approach is to use a sequence autoencoder, which reads the input sequence into a vector and predicts the input sequence again. These two algorithms can be used as a \\"pretraining\\" step for a later supervised sequence learning algorithm. In other words, the parameters obtained from the unsupervised step can be used as a starting point for other supervised training models. In our experiments, we find that long short term memory recurrent networks after being pretrained with the two approaches are more stable and generalize better. With pretraining, we are able to train long short term memory recurrent networks up to a few hundred timesteps, thereby achieving strong performance in many text classification tasks, such as IMDB, DBpedia and 20 Newsgroups."},{"paper_id":"1e077413b25c4d34945cc2707e17e46ed4fe784a","paper_title":"Universal Language Model Fine-tuning for Text Classification","paper_year":2018,"paper_venue":"ACL","paper_citations":332,"paper_abstract":"Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100x more data. We open-source our pretrained models and code."},{"paper_id":"bc8fa64625d9189f5801837e7b133e7fe3c581f7","paper_title":"Learned in Translation: Contextualized Word Vectors","paper_year":2017,"paper_venue":"NIPS","paper_citations":244,"paper_abstract":"Computer vision has benefited from initializing multiple deep layers with weights pretrained on large supervised training sets like ImageNet. Natural language processing (NLP) typically sees initialization of only the lowest layer of deep models with pretrained word vectors. In this paper, we use a deep LSTM encoder from an attentional sequence-to-sequence model trained for machine translation (MT) to contextualize word vectors. We show that adding these context vectors (CoVe) improves performance over using only unsupervised word and character vectors on a wide variety of common NLP tasks: sentiment analysis (SST, IMDb), question classification (TREC), entailment (SNLI), and question answering (SQuAD). For fine-grained sentiment analysis and entailment, CoVe improves performance of our baseline models to the state of the art."},{"paper_id":"7f4afc1bf3272ae6ec00b46e27efc4a4f6b0826d","paper_title":"MaskGAN: Better Text Generation via Filling in the _______","paper_year":2018,"paper_venue":"ICLR","paper_citations":95,"paper_abstract":"Neural text generation models are often autoregressive language models or seq2seq models. Neural autoregressive and seq2seq models that generate text by sampling words sequentially, with each word conditioned on the previous model, are state-of-the-art for several machine translation and summarization benchmarks. These benchmarks are often defined by validation perplexity even though this is not a direct measure of sample quality. Language models are typically trained via maximum likelihood and most often with teacher forcing. Teacher forcing is well-suited to optimizing perplexity but can result in poor sample quality because generating text requires conditioning on sequences of words that were never observed at training time. We propose to improve sample quality using Generative Adversarial Network (GANs), which explicitly train the generator to produce high quality samples and have shown a lot of success in image generation. GANs were originally to designed to output differentiable values, so discrete language generation is challenging for them. We introduce an actor-critic conditional GAN that fills in missing text conditioned on the surrounding context. We show qualitatively and quantitatively, evidence that this produces more realistic text samples compared to a maximum likelihood trained model."},{"paper_id":"bc1d609520290e0460c49b685675eb5a57fa5935","paper_title":"An efficient framework for learning sentence representations","paper_year":2018,"paper_venue":"ICLR","paper_citations":57,"paper_abstract":"In this work we propose a simple and efficient framework for learning sentence representations from unlabelled data. Drawing inspiration from the distributional hypothesis and recent work on learning sentence representations, we reformulate the problem of predicting the context in which a sentence appears as a classification problem. This allows us to efficiently learn different types of encoding functions, and we show that the model learns high-quality sentence representations. We demonstrate that our sentence representations outperform state-of-the-art unsupervised and supervised representation learning methods on several downstream NLP tasks that involve understanding sentence semantics while achieving an order of magnitude speedup in training time."},{"paper_id":"4361e64f2d12d63476fdc88faf72a0f70d9a2ffb","paper_title":"Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units","paper_year":2017,"paper_venue":"ArXiv","paper_citations":45,"paper_abstract":"We propose the Gaussian Error Linear Unit (GELU), a high-performing neural network activation function. The GELU nonlinearity is the expected transformation of a stochastic regularizer which randomly applies the identity or zero map to a neuron\'s input. This stochastic regularizer is comparable to nonlinearities aided by dropout, but it removes the need for a traditional nonlinearity. The connection between the GELU and the stochastic regularizer suggests a new probabilistic understanding of nonlinearities. We perform an empirical evaluation of the GELU nonlinearity against the ReLU and ELU activations and find performance improvements across all tasks."},{"paper_id":"ac11062f1f368d97f4c826c317bf50dcc13fdb59","paper_title":"Dissecting Contextual Word Embeddings: Architecture and Representation","paper_year":2018,"paper_venue":"EMNLP","paper_citations":43,"paper_abstract":"Contextual word representations derived from pre-trained bidirectional language models (biLMs) have recently been shown to provide significant improvements to the state of the art for a wide range of NLP tasks. However, many questions remain as to how and why these models are so effective. In this paper, we present a detailed empirical study of how the choice of neural architecture (e.g. LSTM, CNN, or self attention) influences both end task accuracy and qualitative properties of the representations that are learned. We show there is a tradeoff between speed and accuracy, but all architectures learn high quality contextual representations that outperform word embeddings for four challenging NLP tasks. Additionally, all architectures learn representations that vary with network depth, from exclusively morphological based at the word embedding layer through local syntax based in the lower contextual layers to longer range semantics such coreference at the upper layers. Together, these results suggest that unsupervised biLMs, independent of architecture, are learning much more about the structure of language than previously appreciated."},{"paper_id":"a97dc52807d80454e78d255f9fbd7b0fab56bd03","paper_title":"Discourse-Based Objectives for Fast Unsupervised Sentence Representation Learning","paper_year":2017,"paper_venue":"ArXiv","paper_citations":35,"paper_abstract":"This work presents a novel objective function for the unsupervised training of neural network sentence encoders. It exploits signals from paragraph-level discourse coherence to train these models to understand text. Our objective is purely discriminative, allowing us to train models many times faster than was possible under prior methods, and it yields models which perform well in extrinsic evaluations."},{"paper_id":"b9de9599d7241459db9213b5cdd7059696f5ef8d","paper_title":"Character-Level Language Modeling with Deeper Self-Attention","paper_year":2018,"paper_venue":"AAAI","paper_citations":26,"paper_abstract":"LSTMs and other RNN variants have shown strong performance on character-level language modeling. These models are typically trained using truncated backpropagation through time, and it is common to assume that their success stems from their ability to remember long-term contexts. In this paper, we show that a deep (64-layer) transformer model with fixed context outperforms RNN variants by a large margin, achieving state of the art on two popular benchmarks: 1.13 bits per character on text8 and 1.06 on enwik8. To get good results at this depth, we show that it is important to add auxiliary losses, both at intermediate network layers and intermediate sequence positions."}],[{"paper_id":"83174a52f38c80427e237446ccda79e2a9170742","paper_title":"Deep Sparse Rectifier Neural Networks","paper_year":2011,"paper_venue":"AISTATS","paper_citations":999,"paper_abstract":"While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neurons are an even better model of biological neurons and yield equal or better performance than hyperbolic tangent networks in spite of the hard non-linearity and non-dierentiabil ity"},{"paper_id":"b0130277677e5b915d5cd86b3afafd77fd08eb2e","paper_title":"Estimation of probabilities from sparse data for the language model component of a speech recognizer","paper_year":1987,"paper_venue":"IEEE Trans. Acoustics, Speech, and Signal Processing","paper_citations":999,"paper_abstract":"The description of a novel type of m-gram language model is given. The model offers, via a nonlinear recursive procedure, a computation and space efficient solution to the problem of estimating probabilities from sparse data. This solution compares favorably to other proposed methods. While the method has been developed for and successfully implemented in the IBM Real Time Speech Recognizers, its generality makes it applicable in other areas where the problem of estimating probabilities from sparse data arises."},{"paper_id":"5c3785bc4dc07d7e77deef7e90973bdeeea760a5","paper_title":"TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems","paper_year":2015,"paper_venue":"ArXiv","paper_citations":999,"paper_abstract":"TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org."},{"paper_id":"1827de6fa9c9c1b3d647a9d707042e89cf94abf0","paper_title":"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift","paper_year":2015,"paper_venue":"ICML","paper_citations":999,"paper_abstract":"Training Deep Neural Networks is complicated by the fact that the distribution of each layer\'s inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9% top-5 validation error (and 4.8% test error), exceeding the accuracy of human raters."},{"paper_id":"0b8759d61e93b809df16d9fe9010d2a2d7241c74","paper_title":"Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)","paper_year":2015,"paper_venue":"ICLR","paper_citations":999,"paper_abstract":"Abstract: We introduce the \\"exponential linear unit\\" (ELU) which speeds up learning in deep neural networks and leads to higher classification accuracies. Like rectified linear units (ReLUs), leaky ReLUs (LReLUs) and parametrized ReLUs (PReLUs), ELUs alleviate the vanishing gradient problem via the identity for positive values. However, ELUs have improved learning characteristics compared to the units with other activation functions. In contrast to ReLUs, ELUs have negative values which allows them to push mean unit activations closer to zero like batch normalization but with lower computational complexity. Mean shifts toward zero speed up learning by bringing the normal gradient closer to the unit natural gradient because of a reduced bias shift effect. While LReLUs and PReLUs have negative values, too, they do not ensure a noise-robust deactivation state. ELUs saturate to a negative value with smaller inputs and thereby decrease the forward propagated variation and information. Therefore, ELUs code the degree of presence of particular phenomena in the input, while they do not quantitatively model the degree of their absence. In experiments, ELUs lead not only to faster learning, but also to significantly better generalization performance than ReLUs and LReLUs on networks with more than 5 layers. On CIFAR-100 ELUs networks significantly outperform ReLU networks with batch normalization while batch normalization does not improve ELU networks. ELU networks are among the top 10 reported CIFAR-10 results and yield the best published result on CIFAR-100, without resorting to multi-view evaluation or model averaging. On ImageNet, ELU networks considerably speed up learning compared to a ReLU network with the same architecture, obtaining less than 10% classification error for a single crop, single model network."},{"paper_id":"0d67362a5630ec3b7562327acc278c1c996454b5","paper_title":"Learning Deep Architectures for AI","paper_year":2007,"paper_venue":"Foundations and Trends in Machine Learning","paper_citations":999,"paper_abstract":"Theoretical results strongly suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one needs deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers or in complicated propositional formulae re-using many sub-formulae. Searching the parameter space of deep architectures is a difficult optimization task, but learning algorithms such as those for Deep Belief Networks have recently been proposed to tackle this problem with notable success, beating the state-of-the-art in certain areas. This paper discusses the motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer models such as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks."},{"paper_id":"1eb09fecd75eb27825dce4f964b97f4f5cc399d7","paper_title":"On the Properties of Neural Machine Translation: Encoder-Decoder Approaches","paper_year":2014,"paper_venue":"SSST@EMNLP","paper_citations":999,"paper_abstract":"Neural machine translation is a relatively new approach to statistical machine translation based purely on neural networks. The neural machine translation models often consist of an encoder and a decoder. The encoder extracts a fixed-length representation from a variable-length input sentence, and the decoder generates a correct translation from this representation. In this paper, we focus on analyzing the properties of the neural machine translation using two models; RNN Encoder\u2010Decoder and a newly proposed gated recursive convolutional neural network. We show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase. Furthermore, we find that the proposed gated recursive convolutional network learns a grammatical structure of a sentence automatically."},{"paper_id":"162d958ff885f1462aeda91cd72582323fd6a1f4","paper_title":"Gradient-based learning applied to document recognition","paper_year":1998,"paper_venue":"","paper_citations":999,"paper_abstract":"Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."},{"paper_id":"2f83f6e1afadf0963153974968af6b8342775d82","paper_title":"Framewise phoneme classification with bidirectional LSTM and other neural network architectures","paper_year":2005,"paper_venue":"Neural Networks","paper_citations":999,"paper_abstract":"In this paper, we present bidirectional Long Short Term Memory (LSTM) networks, and a modified, full gradient version of the LSTM learning algorithm. We evaluate Bidirectional LSTM (BLSTM) and several other network architectures on the benchmark task of framewise phoneme classification, using the TIMIT database. Our main findings are that bidirectional networks outperform unidirectional ones, and Long Short Term Memory (LSTM) is much faster and also more accurate than both standard Recurrent Neural Nets (RNNs) and time-windowed Multilayer Perceptrons (MLPs). Our results support the view that contextual information is crucial to speech processing, and suggest that BLSTM is an effective architecture with which to exploit it."},{"paper_id":"d0e51833b3db3af1c762ab723efd08f117a497c8","paper_title":"Improved Training of Wasserstein GANs","paper_year":2017,"paper_venue":"NIPS","paper_citations":999,"paper_abstract":"Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only poor samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models with continuous generators. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms."},{"paper_id":"6de2b1058c5b717878cce4e7e50d3a372cc4aaa6","paper_title":"Generative Adversarial Nets","paper_year":2014,"paper_venue":"NIPS","paper_citations":999,"paper_abstract":"We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to \xbd everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples."},{"paper_id":"1cff7cc15555c38607016aaba24059e76b160adb","paper_title":"Annotating Expressions of Opinions and Emotions in Language","paper_year":2005,"paper_venue":"Language Resources and Evaluation","paper_citations":999,"paper_abstract":"This paper describes a corpus annotation project to study issues in the manual annotation of opinions, emotions, sentiments, speculations, evaluations and other private states in language. The resulting corpus annotation scheme is described, as well as examples of its use. In addition, the manual annotation process and the results of an inter-annotator agreement study on a 10,000-sentence corpus of articles drawn from the world press are presented."},{"paper_id":"160315c07d18fe785aff07f50c9e44319a0af0cb","paper_title":"Policy Gradient Methods for Reinforcement Learning with Function Approximation","paper_year":1999,"paper_venue":"NIPS","paper_citations":999,"paper_abstract":"Function approximation is essential to reinforcement learning, but the standard approach of approximating a value function and determining a policy from it has so far proven theoretically intractable. In this paper we explore an alternative approach in which the policy is explicitly represented by its own function approximator, independent of the value function, and is updated according to the gradient of expected reward with respect to the policy parameters. Williams\'s REINFORCE method and actor-critic methods are examples of this approach. Our main new result is to show that the gradient can be written in a form suitable for estimation from experience aided by an approximate action-value or advantage function. Using this result, we prove for the first time that a version of policy iteration with arbitrary differentiable function approximation is convergent to a locally optimal policy."}]],[[{"paper_id":"05dd7254b632376973f3a1b4d39485da17814df5","paper_title":"SQuAD: 100, 000+ Questions for Machine Comprehension of Text","paper_year":2016,"paper_venue":"EMNLP","paper_citations":926,"paper_abstract":"We present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. \\nThe dataset is freely available at this https URL"},{"paper_id":"766ce989b8b8b984f7a4691fd8c9af4bdb2b74cd","paper_title":"\\"Cloze procedure\\": a new tool for measuring readability.","paper_year":1953,"paper_venue":"","paper_citations":698,"paper_abstract":"Here is the first comprehensive statement of a research method and its theory which were introduced briefly during a workshop at the 1953 AEJ convention. Included are findings from three pilot studies and two experiments in which \u201ccloze procedure\u201d results are compared with those of two readability formulas."},{"paper_id":"007ab5528b3bd310a80d553cccad4b78dc496b02","paper_title":"Bidirectional Attention Flow for Machine Comprehension","paper_year":2016,"paper_venue":"ICLR","paper_citations":611,"paper_abstract":"Machine comprehension (MC), answering a query about a given context paragraph, requires modeling complex interactions between the context and the query. Recently, attention mechanisms have been successfully extended to MC. Typically these methods use attention to focus on a small portion of the context and summarize it with a fixed-size vector, couple attentions temporally, and/or often form a uni-directional attention. In this paper we introduce the Bi-Directional Attention Flow (BIDAF) network, a multi-stage hierarchical process that represents the context at different levels of granularity and uses bi-directional attention flow mechanism to obtain a query-aware context representation without early summarization. Our experimental evaluations show that our model achieves the state-of-the-art results in Stanford Question Answering Dataset (SQuAD) and CNN/DailyMail cloze test."},{"paper_id":"f010affab57b5fcf1cd6be23df79d8ec98c7289c","paper_title":"TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension","paper_year":2017,"paper_venue":"ACL","paper_citations":214,"paper_abstract":"We present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23% and 40% vs. 80%), suggesting that TriviaQA is a challenging testbed that is worth significant future study. Data and code available at -- this http URL"},{"paper_id":"8c1b00128e74f1cd92aede3959690615695d5101","paper_title":"QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension","paper_year":2018,"paper_venue":"ICLR","paper_citations":164,"paper_abstract":"Current end-to-end machine reading and question answering (Q\\\\&A) models are primarily based on recurrent neural networks (RNNs) with attention. Despite their success, these models are often slow for both training and inference due to the sequential nature of RNNs. We propose a new Q\\\\&A model that does not require recurrent networks: It consists exclusively of attention and convolutions, yet achieves equivalent or better performance than existing models. On the SQuAD dataset, our model is 3x to 13x faster in training and 4x to 9x faster in inference. The speed-up gain allows us to train the model with much more data. We hence combine our model with data generated by backtranslation from a neural machine translation model. This data augmentation technique not only enhances the training examples but also diversifies the phrasing of the sentences, which results in immediate accuracy improvements. Our single model achieves 84.6 F1 score on the test set, which is significantly better than the best published F1 score of 81.8."},{"paper_id":"3c78c6df5eb1695b6a399e346dde880af27d1016","paper_title":"Simple and Effective Multi-Paragraph Reading Comprehension","paper_year":2017,"paper_venue":"ACL","paper_citations":96,"paper_abstract":"We consider the problem of adapting neural paragraph-level question answering models to the case where entire documents are given as input. Our proposed solution trains models to produce well calibrated confidence scores for their results on individual paragraphs. We sample multiple paragraphs from the documents during training, and use a shared-normalization training objective that encourages the model to produce globally correct output. We combine this method with a state-of-the-art pipeline for training models on document QA data. Experiments demonstrate strong performance on several document QA datasets. Overall, we are able to achieve a score of 71.3 F1 on the web portion of TriviaQA, a large improvement from the 56.7 F1 of the previous best system."},{"paper_id":"e0222a1ae6874f7fff128c3da8769ab95963da04","paper_title":"Reinforced Mnemonic Reader for Machine Reading Comprehension","paper_year":2017,"paper_venue":"IJCAI","paper_citations":46,"paper_abstract":"In this paper, we introduce the Reinforced Mnemonic Reader for machine reading comprehension tasks, which enhances previous attentive readers in two aspects. First, a reattention mechanism is proposed to refine current attentions by directly accessing to past attentions that are temporally memorized in a multi-round alignment architecture, so as to avoid the problems of attention redundancy and attention deficiency. Second, a new optimization approach, called dynamic-critical reinforcement learning, is introduced to extend the standard supervised method. It always encourages to predict a more acceptable answer so as to address the convergence suppression problem occurred in traditional reinforcement learning algorithms. Extensive experiments on the Stanford Question Answering Dataset (SQuAD) show that our model achieves state-of-the-art results. Meanwhile, our model outperforms previous systems by over 6% in terms of both Exact Match and F1 metrics on two adversarial SQuAD datasets."},{"paper_id":"26b47e35fe6e4260fdf7b7cc98f279a73c277494","paper_title":"Multi-granularity hierarchical attention fusion networks for reading comprehension and question answering","paper_year":2018,"paper_venue":"ACL","paper_citations":35,"paper_abstract":"This paper describes a novel hierarchical attention network for reading comprehension style question answering, which aims to answer questions for a given narrative paragraph. In the proposed method, attention and fusion are conducted horizontally and vertically across layers at different levels of granularity between question and paragraph. Specifically, it first encode the question and paragraph with fine-grained language embeddings, to better capture the respective representations at semantic level. Then it proposes a multi-granularity fusion approach to fully fuse information from both global and attended representations. Finally, it introduces a hierarchical attention network to focuses on the answer span progressively with multi-level softalignment. Extensive experiments on the large-scale SQuAD and TriviaQA datasets validate the effectiveness of the proposed method. At the time of writing the paper (Jan. 12th 2018), our model achieves the first position on the SQuAD leaderboard for both single and ensemble models. We also achieves state-of-the-art results on TriviaQA, AddSent and AddOne-Sent datasets."},{"paper_id":"27e98e09cf09bc13c913d01676e5f32624011050","paper_title":"U-Net: Machine Reading Comprehension with Unanswerable Questions","paper_year":2018,"paper_venue":"ArXiv","paper_citations":8,"paper_abstract":"Machine reading comprehension with unanswerable questions is a new challenging task for natural language processing. A key subtask is to reliably predict whether the question is unanswerable. In this paper, we propose a unified model, called U-Net, with three important components: answer pointer, no-answer pointer, and answer verifier. We introduce a universal node and thus process the question and its context passage as a single contiguous sequence of tokens. The universal node encodes the fused information from both the question and passage, and plays an important role to predict whether the question is answerable and also greatly improves the conciseness of the U-Net. Different from the state-of-art pipeline models, U-Net can be learned in an end-to-end fashion. The experimental results on the SQuAD 2.0 dataset show that U-Net can effectively predict the unanswerability of questions and achieves an F1 score of 71.7 on SQuAD 2.0."}],[]]],"clusterNames":["visual question answering","textual similarity","named entity","word embeddings","neural networks","reading comprehension"]}')},163:function(e,t,a){e.exports=a(322)},168:function(e,t,a){},169:function(e,t,a){},174:function(e,t){},176:function(e,t){},211:function(e,t){},212:function(e,t){},256:function(e,t,a){},257:function(e,t,a){},258:function(e,t,a){},322:function(e,t,a){"use strict";a.r(t);var n=a(0),i=a.n(n),r=a(146),o=a.n(r),s=(a(168),a(11)),c=a(12),l=a(14),d=a(13),p=a(15),h=(a(169),a(147)),u=a(54),m=a(150),f=a(152),g=a(149),b=a(151),v=a(148),y=a(154),w=a(153),_=a(1),x=a.n(_),k=a(55),T=a.n(k),E=(a(256),x()("green").luminance(.3).desaturate(1)),S=x()("red").luminance(.3).desaturate(2),L=x()("blue").luminance(.3).desaturate(1),N=x()("grey").luminance(.3),I=x()("grey").luminance(.1),A=function(e){function t(e){var a;return Object(s.a)(this,t),(a=Object(l.a)(this,Object(d.a)(t).call(this,e))).state={hover:!1},a}return Object(p.a)(t,e),Object(c.a)(t,[{key:"onHover",value:function(e){this.setState({hover:e}),this.props.onHover&&this.props.onHover(e)}},{key:"render",value:function(){var e=this;return i.a.createElement("circle",{className:"era-node-circle",cx:this.props.node.x,cy:this.props.node.y,r:this.props.radius,onMouseOver:function(){e.onHover(!0)},onMouseLeave:function(){e.onHover(!1)},stroke:this.props.color,strokeWidth:this.props.strokeWidth,fill:this.state.hover?this.props.color:"white"})}}]),t}(i.a.Component),C=function(e){function t(e){var a;return Object(s.a)(this,t),(a=Object(l.a)(this,Object(d.a)(t).call(this,e))).state={displayInteractionTool:!1},a.id=T.a.generate(8),a.state={expand:-1},a}return Object(p.a)(t,e),Object(c.a)(t,[{key:"onEdit",value:function(e,t){this.props.onEdit&&this.props.onEdit(e,t)}},{key:"onHover",value:function(e){e||-1===this.state.expand||this.setState({expand:-1})}},{key:"render",value:function(){var e=this,t=x()(this.props.color).darken(),a=0,n=0,r=1.25*this.props.lineHeight,o=this.props.pins.map((function(o,s){a=n*e.props.lineHeight;var c=e.state.expand===s,l=function(){return e.setState({expand:c?-1:s})},d=c?o.fullTextPieces:o.textPieces,p=o.abstractPieces.length*e.props.secondaryLineHeight,h=(d.length-1)*e.props.lineHeight+e.props.editButtonMarginTop+c*p,u=c?e.props.fullTextWidth:e.props.textWidth,_=function(t,a,n,s){return i.a.createElement("g",{transform:"translate(".concat(u-r*a,", ").concat(h,")")},i.a.createElement("g",{className:"paper-edit-icon",style:{transformOrigin:"".concat(r/2,"px ").concat(r/2,"px")},onClick:"collapse"===s?l:function(){return e.onEdit(s,o)}},i.a.createElement(t,{className:"paper-edit-icon",fill:n,width:r,height:r}),i.a.createElement("rect",{className:"paper-edit-icon",width:r,height:r,fill:"transparent"})))},x=o.edits&&o.edits.rate>0,k=o.edits&&o.edits.rate<0,T="left"===e.props.scaleOrigin?0:"middle"===e.props.scaleOrigin?u/2:u;return i.a.createElement("g",{className:"paper-view-group-outer",key:s,onMouseOver:function(){return e.onHover(!0)},onMouseLeave:function(){return e.onHover(!1)},transform:"translate(".concat(e.props.textLeadingMargin+e.props.radius,", ").concat(a,")")},i.a.createElement("g",{className:"paper-view-group-inner",style:{transformOrigin:"".concat(T,"px ").concat(-e.props.lineHeight,"px")}},i.a.createElement("rect",{className:"paper-text-background",x:-e.props.lineHeight,y:2.5*-e.props.lineHeight,width:u+2*e.props.lineHeight,height:4*e.props.lineHeight+h+r,fill:"white",filter:"url(#blur-filter)"}),i.a.createElement("text",{className:"paper-text",fontSize:e.props.fontSize,fill:t,onClick:l},d.map((function(t,a){return n++,i.a.createElement("tspan",{key:a,x:"0",y:a*e.props.lineHeight},t)}))),c&&i.a.createElement("text",{className:"paper-abstract-inner",fontSize:e.props.secondaryFontSize,fill:I},o.abstractPieces.map((function(t,a){return i.a.createElement("tspan",{key:a,x:"0",y:d.length*e.props.lineHeight+a*e.props.secondaryLineHeight},t)}))),i.a.createElement("g",{className:"paper-edit-icon-group"},e.props.editable&&_(v.a,6,L,"to-exchange"),_(x?g.a:m.a,4.5,E,x?"thumb-delete":"thumb-up"),_(k?b.a:f.a,3,S,k?"thumb-delete":"thumb-down"),o.abstractPieces.length>0&&_(c?w.a:y.a,1.5,N,"collapse"))))}));return i.a.createElement("g",{className:"era-node-text-group",transform:"translate(".concat(this.props.x,", ").concat(this.props.y,")")},o.reverse())}}]),t}(i.a.Component),W=a(58),M=a.n(W);a(257);function z(){return(z=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var a=arguments[t];for(var n in a)Object.prototype.hasOwnProperty.call(a,n)&&(e[n]=a[n])}return e}).apply(this,arguments)}function q(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var R=i.a.createElement("path",{d:"M520.650142 80.061167L369.746208 410.281909l269.859169-71.853003 1.641632-0.631397-120.596867-257.736342z",fill:"#E9624C"}),P=i.a.createElement("path",{d:"M256.852386 657.03194l385.909977 121.859662 100.392157-222.756937-76.272784-163.279319-333.251449 96.098656-76.777901 168.077938z",fill:"#2A698D"}),O=i.a.createElement("path",{d:"M92.689111 1015.791836h865.266741L773.966704 622.052534l-102.286349 232.227895-442.735726-136.381798L92.689111 1015.791836z",fill:"#233D7E"}),D=i.a.createElement("path",{d:"M484.281662 0H0v1015.791836h6.187693L483.650265 1.641633l0.631397-1.641633zM555.376989 0l0.505117 1.136515 483.271427 1014.655321h4.293501V0H555.376989z",fill:"#3C3837"}),F=function(e){var t=e.svgRef,a=e.title,n=q(e,["svgRef","title"]);return i.a.createElement("svg",z({viewBox:"0 0 1024 1024",ref:t},n),a?i.a.createElement("title",null,a):null,R,P,O,D)},j=i.a.forwardRef((function(e,t){return i.a.createElement(F,z({svgRef:t},e))}));a.p;function B(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function U(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?B(a,!0).forEach((function(t){Object(u.a)(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):B(a).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}var H=function(e){function t(e){var a;return Object(s.a)(this,t),(a=Object(l.a)(this,Object(d.a)(t).call(this,e))).EraMinRatio=a.props.EraMinRatio||.05,a.lastEraRatio=a.props.lastEraRatio||.2,a.strokeWidth=4,a.labelTextFontSize=64,a.labelTextLineHeight=72,a.nodeRadius=20,a.nodeTextLeadingMargin=20,a.nodeTextWidth=260,a.nodeFullSpan=2,a.horizonMarginTop=32,a.horizonMarginBottom=48,a.averageFontWidthRatio=.6,a.nodePaddingLeft=20,a.nodePaddingRight=20,a.nodePaddingTop=32,a.nodePaddingBottom=12,a.nodeEditButtonMarginTop=10,a.nodeOffsetX=a.nodePaddingLeft+a.nodeRadius,a.nodeOffsetY=a.nodePaddingTop+a.nodeRadius,a.nodeWidth=a.nodePaddingLeft+2*a.nodeRadius+a.nodeTextLeadingMargin+a.nodeTextWidth+a.nodePaddingRight,a.nodeTextLines=function(e){return e.pins.reduce((function(e,t){return e+t.textPieces.length}),0)},a.nodeHeight=function(e){return a.nodePaddingTop+a.nodeRadius+Math.max(a.nodeRadius,(e-1)*a.nodeTextLineHeight)+a.nodePaddingBottom},a.state={userEdits:a.props.userEdits||{},toExchange:null,focusEraIndex:-1},a}return Object(p.a)(t,e),Object(c.a)(t,[{key:"render",value:function(){var e=this;this._data=this.props.data;var t=function(e){var t=e.paper_id,a=e.paper_year,n=e.paper_venue.trim(),i=e.paper_title.trim(),r=e.paper_citations,o="".concat(a),s=/^(19|20)\d{2}\b/.exec(n);return null==s&&n.length>0?o="".concat(a," ").concat(n):null!=s&&(o="".concat(n)),{id:t,year:a,venue:n,title:i,citations:r,text:"[".concat(o,"] ").concat(i).replace("\t"," ").replace("\n"," "),abstract:e.paper_abstract?e.paper_abstract.trim().replace("\t"," "):""}};this.data={root:t(this._data.root),branches:[]},this._data.branches.forEach((function(a){e.data.branches.push(a[0].map(t)),e.data.branches.push(a[1].map(t))})),this.data.branches.forEach((function(e){return e.sort((function(e,t){return e.year===t.year?t.citations-e.citations:t.year-e.year}))})),this.clusterNames=this.props.data.clusterNames.map((function(e){return e.split(" ").map(M.a.capitalize).join(" ")})),this.hideSubBranch=this.props.hideSubBranch,this.disableTextBranchSpan=this.props.disableTextBranchSpan,this.disableTextClusterSpan=this.props.disableTextClusterSpan,this.nodeFontExtraSize=this.props.fontExtraSize||0,this.nodeTextFontSize=20+this.nodeFontExtraSize,this.nodeTextSecondaryFontSize=16+this.nodeFontExtraSize,this.nodeTextLineHeight=20+this.nodeFontExtraSize,this.nodeTextSecondaryLineHeight=18+this.nodeFontExtraSize,this.nodeTextFold=function(t,a){var n=Math.floor(((a-1)*e.nodeWidth+e.nodeTextWidth)/(e.nodeTextFontSize*e.averageFontWidthRatio));return(t.match(new RegExp("([^\\n]{1,".concat(n,"})(\\s|$)"),"g"))||[]).filter((function(e){return e.length>0}))},this.nodeTextSecondaryFold=function(t,a){var n=Math.floor(((a-1)*e.nodeWidth+e.nodeTextWidth)/(e.nodeTextSecondaryFontSize*e.averageFontWidthRatio));return(t.match(new RegExp("([^\\n]{1,".concat(n,"})(\\s|$)"),"g"))||[]).filter((function(e){return e.length>0}))};var a={root:U({},this.data.root),branches:this.data.branches.map((function(){return[]}))};this.data.branches.forEach((function(t,n){return t.forEach((function(t){var i=n%2===1,r=e.state.userEdits[t.id],o=r?r.clusterID:Math.floor(n/2),s=2*o+i;e.hideSubBranch&&i||a.branches[s].push(U({},t,{isSub:i,edits:r,clusterID:o,branchID:s}))}))})),a.branches.forEach((function(e){return e.sort((function(e,t){return e.year===t.year?t.citations-e.citations:t.year-e.year}))}));for(var n=[],r=M.a.flatten(a.branches).map((function(e){return e.year})).sort().reverse(),o=r[0],s=1,c=this.EraMinRatio*r.length,l=this.lastEraRatio*r.length,d=1;d<r.length;d++)r[d]===r[d-1]||s<c||d>r.length-l?s+=1:(n.push({from:r[d-1],to:o,cnt:s}),o=r[d],s=1);n.push({from:r[r.length-1],to:o,cnt:s});var p=function(e,t){return e.filter((function(e){return e.year>=t.from&&e.year<=t.to}))},h=a.branches.length,u=Math.floor(h/2),m=x.a.scale()(.5),f=x.a.cubehelix().start(200).rotations(3).gamma(.7).lightness([.2,.6]).scale().correctLightness().colors(u),g=a.branches.map((function(e,t){return x()(f[Math.floor(t/2)]).luminance(t%2===0?.25:.5)})),b={defs:[],nodes:{},edges:[]},v=function(t,a,n,r,o){return b.edges.push(i.a.createElement("line",{key:b.edges.length,x1:t,y1:a,x2:n,y2:r,strokeWidth:e.strokeWidth-1,stroke:o}))},y=function(e,t,a,n){return v(e,t,e,a,n)},w=function(e,t,a,n){return v(e,a,t,a,n)},_=function(e,t,a,n,r,o){var s=T.a.generate(8);return b.defs.push(i.a.createElement("defs",{key:s},i.a.createElement("linearGradient",{id:s,x1:a,y1:n,x2:r,y2:o,gradientUnits:"userSpaceOnUse"},i.a.createElement("stop",{offset:"20%",stopColor:e}),i.a.createElement("stop",{offset:"80%",stopColor:t})))),"url('#".concat(s,"')")};b.nodes.root={x:this.nodeWidth*(a.branches.length-1)/2+this.nodeOffsetX,y:this.nodeOffsetY,color:m,pins:[U({},a.root,{textPieces:this.nodeTextFold(a.root.text,2),fullTextPieces:this.nodeTextFold(a.root.text,this.nodeFullSpan),abstractPieces:this.nodeTextSecondaryFold(a.root.abstract,this.nodeFullSpan),edits:this.state.userEdits[a.root.id]})],span:2,fullSpan:this.nodeFullSpan},b.nodes.root.lines=this.nodeTextLines(b.nodes.root),b.nodes.root.height=this.nodeHeight(b.nodes.root.lines),b.nodes.branches=a.branches.map((function(t,a){return n.map((function(n,i){return{x:e.nodeWidth*a+e.nodeOffsetX,y:0,color:g[a],pins:p(t,n),era:n,eraID:i,clusterID:Math.floor(a/2),branchID:a}}))})),b.nodes.branches.forEach((function(t,a){return t.forEach((function(t,n){0!==t.pins.length&&(t.span=!(a<h-1&&0===b.nodes.branches[a+1][n].pins.length)||e.disableTextBranchSpan||e.disableTextClusterSpan&&a%2!==0?1:2,t.fullSpan=a<h-1?e.nodeFullSpan:1,t.pins.forEach((function(a){a.textPieces=e.nodeTextFold(a.text,t.span),a.fullTextPieces=e.nodeTextFold(a.text,t.fullSpan),a.abstractPieces=e.nodeTextSecondaryFold(a.abstract,t.fullSpan)})),t.lines=e.nodeTextLines(t),t.height=e.nodeHeight(t.lines))}))}));var k=b.nodes.root.height+this.horizonMarginTop,E=k+this.horizonMarginBottom,S=n.map((function(t,a){b.nodes.branches.forEach((function(t){return t[a].y=E+e.nodeOffsetY}));var n=b.nodes.branches.reduce((function(e,t){return Math.max(e,t[a].height||0)}),0);return E+=n,n})),L=b.nodes.root,N=b.nodes.branches[0][0],I=b.nodes.branches[h-2][0];y(L.x,L.y,k,m),w(N.x,I.x,k,m),b.nodes.branches.forEach((function(t,a){var n=t.filter((function(e){return e.pins.length>0}));if(0!==n.length||a%2!==1){var i=a%2===0?0:n[0].eraID,r=n.length>0?n[n.length-1].eraID:0;if(a%2===0){var o=b.nodes.branches[a+1].filter((function(e){return e.pins.length>0}));o.length>0&&(r=Math.max(r,o[0].eraID))}for(var s=!e.disableTextBranchSpan&&!(e.disableTextClusterSpan&&a%2===0),c=i+1;c<=r;c++){var l=t[c],d=a>0?b.nodes.branches[a-1][c]:null,p=s&&0===l.pins.length&&(a>0&&d.pins.length>0||c===r)?l.y-e.nodeRadius-e.nodeTextLineHeight:l.y;l=t[c-1],d=a>0?b.nodes.branches[a-1][c-1]:null;var h=s&&0===l.pins.length&&a>0&&d.pins.length>0?l.y-e.nodeOffsetY+e.nodeHeight(e.nodeTextLines(d))-e.nodePaddingBottom+e.nodeTextLineHeight:l.y;y(l.x,p,h,l.color)}if(a%2===0){var u=t[0],f=a>0?b.nodes.branches[a-1][0]:null,g=s&&0===u.pins.length&&a>0&&f.pins.length>0?u.y-e.nodeRadius-e.nodeTextLineHeight:u.y;y(u.x,k,g,_(m,u.color,u.x,k,u.x,g))}else{var v=t[i],x=b.nodes.branches[a-1][i],T=v.y-e.nodeRadius-e.nodeTextLineHeight,E=v.y;y(v.x,E,T,v.color),w(v.x,x.x,T,_(v.color,x.color,v.x,T,x.x,T))}}}));var W=function(t,a,n){var i=U({},e.state);i.userEdits[a.id]||"thumb-up"!==t&&"thumb-down"!==t&&"exchange"!==t||(i.userEdits[a.id]={rate:0,clusterID:a.clusterID}),"thumb-up"===t&&i.userEdits[a.id].rate<=0?(i.userEdits[a.id].rate=1,e.setState(i)):"thumb-down"===t&&i.userEdits[a.id].rate>=0?(i.userEdits[a.id].rate=-1,e.setState(i)):"thumb-delete"===t&&i.userEdits[a.id]&&0!==i.userEdits[a.id].rate?(i.userEdits[a.id].rate=0,e.setState(i)):"to-exchange"===t&&null===i.toExchange?(i.toExchange=a,e.setState(i)):"exchange"===t&&(i.userEdits[a.id].clusterID=n,i.toExchange=null,e.setState(i))},z=b.nodes.branches.map((function(e){return e[e.length-1]})).reduce((function(t,a){var n=a.y;return a.pins.forEach((function(a){t=Math.max(t,n+(a.fullTextPieces.length-1)*e.nodeTextLineHeight*2+a.abstractPieces.length*e.nodeTextSecondaryLineHeight+2*e.nodeTextLineHeight),n+=a.textPieces.length*e.nodeTextLineHeight})),t}),E),q=M.a.flattenDeep(b.nodes.branches).sort((function(e,t){return e.eraID===t.eraID?t.branchID-e.branchID:t.eraID-e.eraID}));q.push(b.nodes.root);var R=this.nodeWidth*a.branches.length,P=this.clusterNames.map((function(e){return e.split(" ")})),O=P.map((function(t,a){return i.a.createElement("text",{key:a},t.reverse().map((function(t,a){return i.a.createElement("tspan",{key:a,x:"0",y:-a*e.labelTextLineHeight},t)})))})),D=P.reduce((function(e,t){return Math.max(e,t.length)}),0)*this.labelTextLineHeight;E+=D+this.labelTextLineHeight;var F=Math.max(1.5*this.labelTextLineHeight,z-E),B=f.map((function(e){return x()(e).luminance(.9)})),H=f.map((function(e){return x()(e).luminance(.7)})),G=f.map((function(e,t){var a=b.nodes.branches[2*t][n.length-1].x;return _(x()(e).luminance(.9),"white",a,E,a,E+F)})),V=f.map((function(e){return x()(e).luminance(.5)})),Q=f.map((function(e){return x()(e).luminance(.2)})),J=f.map((function(e,t){var a=b.nodes.branches[2*t][n.length-1].x;return _(x()(e).luminance(.5),"white",a,E,a,E+F)}));return i.a.createElement("svg",{className:"mrt",id:this.props.id,width:"100%",viewBox:"0 0 ".concat(R," ").concat(E+F)},b.defs,i.a.createElement("filter",{id:"blur-filter"},i.a.createElement("feGaussianBlur",{stdDeviation:this.nodeTextLineHeight,in:"SourceGraphic"})),i.a.createElement("g",{className:"mrt-background"},i.a.createElement("rect",{x:"0",y:"0",width:R,height:k,fill:x()(m).luminance(.9)})),O.map((function(t,a){return i.a.createElement("g",{className:"mrt-background",key:a,opacity:null===e.state.toExchange?1:0},i.a.createElement("rect",{x:e.nodeWidth*a*2,y:k,width:2*e.nodeWidth,height:E-k,fill:B[a]}),i.a.createElement("rect",{x:e.nodeWidth*a*2,y:E,width:2*e.nodeWidth,height:F,fill:G[a]}),i.a.createElement("g",{transform:"translate(".concat(e.nodeWidth*a*2+e.nodeOffsetX,", ").concat(E-e.labelTextLineHeight/2,")"),fill:H[a],fontSize:e.labelTextFontSize},t))})),n.map((function(t,a){return i.a.createElement("g",{key:a,className:"mrt-era-background",transform:"translate(0, ".concat(b.nodes.branches[0][a].y-e.nodeRadius-e.nodePaddingTop+S[a],")")},i.a.createElement("rect",{className:"mrt-era-background",x:"0",y:-S[a],width:R,height:S[a],opacity:a===e.state.focusEraIndex?.1:0}),i.a.createElement("text",{className:"mrt-era-background",fontSize:e.labelTextFontSize,x:e.nodePaddingLeft,y:-e.labelTextFontSize/2,opacity:a===e.state.focusEraIndex?.2:0},t.from===t.to?t.from:"".concat(t.from," - ").concat(t.to)))})),b.nodes.branches.map((function(t,a){if(a%2!==0)return i.a.createElement("text",{key:a});var n=t.filter((function(e){return e.pins.length>0})),r=b.nodes.branches[a+1].filter((function(e){return e.pins.length>0}));if(0===n.length&&0===r.length)return i.a.createElement("text",{key:a});var o=2*e.nodeTextFontSize,s=(0===n.length||r.length>0&&r[0].eraID<=n[0].eraID?r[0].y-e.nodeRadius-e.nodeTextLineHeight:n[0].y-e.nodeTextLineHeight)-o/2,c=t[0].x+e.nodeRadius+e.nodeTextLeadingMargin,l=x()(g[a]).darken(2);return i.a.createElement("text",{key:a,x:c,y:s,fill:l,fontSize:o},e.clusterNames[Math.floor(a/2)])})),b.edges,q.map((function(t,a){return t.pins.length>0&&i.a.createElement(A,{key:a,node:t,radius:e.nodeRadius,lineHeight:e.nodeTextLineHeight,color:t.color,strokeWidth:e.strokeWidth,onHover:function(a){return e.setState(U({},e.state,{focusEraIndex:a?t.eraID:-1}))}})})),i.a.createElement("g",{className:"mrt-node-text-container"},q.map((function(t,a){return t.pins.length>0&&i.a.createElement(C,{key:a,pins:t.pins,x:t.x,y:t.y,radius:e.nodeRadius,lineHeight:e.nodeTextLineHeight,secondaryLineHeight:e.nodeTextSecondaryLineHeight,textWidth:(t.span-1)*e.nodeWidth+e.nodeTextWidth,fullTextWidth:(t.fullSpan-1)*e.nodeWidth+e.nodeTextWidth,color:t.color,fontSize:e.nodeTextFontSize,secondaryFontSize:e.nodeTextSecondaryFontSize,strokeWidth:e.strokeWidth,onEdit:W,textLeadingMargin:e.nodeTextLeadingMargin,editable:"undefined"!==typeof t.clusterID,editButtonMarginTop:e.nodeEditButtonMarginTop,scaleOrigin:t.clusterID===u-1?"right":t.branchID===h-3?"middle":"left"})}))),O.map((function(t,a){var n=null!==e.state.toExchange&&a===e.state.toExchange.clusterID;return i.a.createElement("g",{className:"mrt-background",key:a,opacity:null===e.state.toExchange?0:1,visibility:null===e.state.toExchange?"hidden":"none",onClick:function(){return W("exchange",e.state.toExchange,a)}},i.a.createElement("rect",{className:"mrt-background-card",x:e.nodeWidth*a*2,y:k,width:2*e.nodeWidth,height:E-k,fill:V[a]}),i.a.createElement("rect",{className:"mrt-background-card",x:e.nodeWidth*a*2,y:E,width:2*e.nodeWidth,height:F,fill:J[a]}),i.a.createElement("g",{className:"mrt-background-text",style:{textDecoration:n?"underline":""},transform:"translate(".concat(e.nodeWidth*a*2+e.nodeOffsetX,", ").concat(E-e.labelTextLineHeight/2,")"),fill:Q[a],fontSize:e.labelTextFontSize},t))})),i.a.createElement("g",{opacity:"0.5",transform:"translate(".concat(R,", ").concat(E+F-.5*this.labelTextLineHeight,")")},i.a.createElement(j,{x:3.35*-this.labelTextFontSize,y:1.78*-this.labelTextFontSize,height:.8*this.labelTextFontSize,width:.8*this.labelTextFontSize}),i.a.createElement("text",{x:.1*-this.labelTextFontSize,y:.05*-this.labelTextFontSize,textAnchor:"end",fontSize:.75*this.labelTextFontSize,fill:x()("grey").luminance(.3).hex()},(this.props.authors||[]).join(", ")),i.a.createElement("text",{x:.1*-this.labelTextFontSize,y:1*-this.labelTextFontSize,textAnchor:"end",fontSize:.7*this.labelTextFontSize,fill:x()("grey").luminance(.3).hex()},"AMiner")))}}]),t}(i.a.Component),G=a(324),V=(a(258),a(90)),Q=a.n(V),J=a(155),X=a.n(J);function K(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function Y(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?K(a,!0).forEach((function(t){Object(u.a)(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):K(a).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}var $=function(e){function t(e){var a;return Object(s.a)(this,t),(a=Object(l.a)(this,Object(d.a)(t).call(this,e))).state={userEdits:a.props.userEdits||{},like:a.props.like||!1,viewerScale:100,hideSubBranch:!1,disableTextClusterSpan:!1,fontExtraSize:0,displayQRCode:!1},a.generated=!1,a}return Object(p.a)(t,e),Object(c.a)(t,[{key:"like",value:function(){this.setState(Y({},this.state,{like:!this.state.like}))}},{key:"capture",value:function(e){if(e)Q.a.saveSvgAsPng(document.getElementById("mrt-viewer"),"master-reading-tree.png");else{var t=document.getElementById("mrt-viewer").viewBox.baseVal.width,a=document.body.clientWidth;Q.a.saveSvgAsPng(document.getElementById("mrt-viewer"),"master-reading-tree-snapshot.png",{scale:a/t})}}},{key:"zoom",value:function(e){this.setState(Y({},this.state,{viewerScale:Math.min(Math.max(this.state.viewerScale+(e?10:-10),100),1e3)}))}},{key:"scaleFont",value:function(e){this.setState(Y({},this.state,{fontExtraSize:Math.max(0,Math.min(10,this.state.fontExtraSize+(e?2:-2)))}))}},{key:"displayQRCode",value:function(e){this.generated||(X.a.toCanvas(document.getElementById("mrt-share-qrcode-canvas"),window.location.href,(function(e){e&&console.error(e)})),this.generated=!0),this.setState(Y({},this.state,{displayQRCode:e}))}},{key:"onLoadJson",value:function(e){var t=this;if(0!==e.target.files.length){var a=new FileReader;a.onload=function(e){t.props.onLoadJson&&t.props.onLoadJson(JSON.parse(e.target.result))},a.readAsText(e.target.files[0])}}},{key:"render",value:function(){var e=this;return i.a.createElement("div",{className:"mrt-container",style:{width:"".concat(this.state.viewerScale,"%")}},i.a.createElement("div",{className:"mrt-toolbox mrt-toolbox-menu horizontal"},i.a.createElement("div",{className:"menu-item horizontal-secondary mrt-toolbox-tool-icon",onClick:function(){return e.like()}},i.a.createElement(G.a,{type:"heart",theme:this.state.like?"filled":"twoTone",twoToneColor:x()("red").luminance(.4).hex(),style:{color:x()("red").luminance(.4).hex()}})),i.a.createElement("div",{className:"menu-item horizontal-secondary mrt-toolbox-menu vertical"},i.a.createElement("div",{className:"menu-item mrt-toolbox-tool-icon"},i.a.createElement(G.a,{type:"share-alt",theme:"outlined",style:{color:x()("green").luminance(.4).hex()}})),i.a.createElement("div",{className:"menu-item vertical-secondary mrt-toolbox-tool-icon",onMouseOver:function(){return e.displayQRCode(!0)},onMouseLeave:function(){return e.displayQRCode(!1)}},i.a.createElement(G.a,{type:"qrcode",theme:"outlined",style:{color:x()("green").luminance(.2).hex()}}))),i.a.createElement("div",{className:"menu-item horizontal-secondary mrt-toolbox-menu vertical"},i.a.createElement("div",{className:"menu-item mrt-toolbox-tool-icon"},i.a.createElement(G.a,{type:"font-size",theme:"outlined",style:{color:x()("pink").luminance(.4).hex()}})),i.a.createElement("div",{className:"menu-item vertical-secondary mrt-toolbox-tool-icon",onClick:function(){return e.scaleFont(!0)}},i.a.createElement(G.a,{type:"zoom-in",theme:"outlined",style:{color:x()("pink").luminance(.2).hex()}})),i.a.createElement("div",{className:"menu-item vertical-secondary mrt-toolbox-tool-icon",onClick:function(){return e.scaleFont(!1)}},i.a.createElement(G.a,{type:"zoom-out",theme:"outlined",style:{color:x()("pink").luminance(.2).hex()}}))),i.a.createElement("div",{className:"menu-item horizontal-secondary mrt-toolbox-menu vertical"},i.a.createElement("div",{className:"menu-item mrt-toolbox-tool-icon"},i.a.createElement(G.a,{type:"search",theme:"outlined",style:{color:x()("aquamarine").luminance(.4).hex()}})),i.a.createElement("div",{className:"menu-item vertical-secondary mrt-toolbox-tool-icon",onClick:function(){return e.zoom(!0)}},i.a.createElement(G.a,{type:"zoom-in",theme:"outlined",style:{color:x()("aquamarine").luminance(.2).hex()}})),i.a.createElement("div",{className:"menu-item vertical-secondary mrt-toolbox-tool-icon",onClick:function(){return e.zoom(!1)}},i.a.createElement(G.a,{type:"zoom-out",theme:"outlined",style:{color:x()("aquamarine").luminance(.2).hex()}}))),i.a.createElement("div",{className:"menu-item horizontal-secondary mrt-toolbox-menu vertical"},i.a.createElement("div",{className:"menu-item mrt-toolbox-tool-icon"},i.a.createElement(G.a,{type:"download",theme:"outlined",style:{color:x()("blue").luminance(.4).hex()}})),i.a.createElement("div",{className:"menu-item vertical-secondary mrt-toolbox-tool-icon",onClick:function(){return e.capture(!0)}},i.a.createElement(G.a,{type:"file-image",theme:"twoTone",twoToneColor:x()("blue").luminance(.2).hex()})),i.a.createElement("div",{className:"menu-item vertical-secondary mrt-toolbox-tool-icon",onClick:function(){return e.capture(!1)}},i.a.createElement(G.a,{type:"camera",theme:"twoTone",twoToneColor:x()("blue").luminance(.2).hex()}))),i.a.createElement("div",{className:"menu-item horizontal-secondary mrt-toolbox-menu vertical"},i.a.createElement("div",{className:"menu-item mrt-toolbox-tool-icon"},i.a.createElement(G.a,{type:"control",theme:"outlined",style:{color:x()("teal").luminance(.4).hex()}})),i.a.createElement("div",{className:"menu-item vertical-secondary mrt-toolbox-tool-icon",onClick:function(){return e.setState(Y({},e.state,{hideSubBranch:!e.state.hideSubBranch}))}},i.a.createElement(G.a,{type:"eye".concat(this.state.hideSubBranch?"":"-invisible"),theme:"twoTone",twoToneColor:x()("teal").luminance(.2).hex()})),i.a.createElement("div",{className:"menu-item vertical-secondary mrt-toolbox-tool-icon",onClick:function(){return e.setState(Y({},e.state,{disableTextClusterSpan:!e.state.disableTextClusterSpan}))}},i.a.createElement(G.a,{type:"column-width",theme:"outlined",style:{color:x()("teal").luminance(.2).hex()}})),i.a.createElement("div",{className:"menu-item vertical-secondary mrt-toolbox-tool-icon",onClick:function(){return document.getElementById("mrt-file-load-input").click()}},i.a.createElement(G.a,{type:"folder-open",theme:"outlined",style:{color:x()("teal").luminance(.2).hex()}}),i.a.createElement("input",{id:"mrt-file-load-input",type:"file",hidden:!0,onChange:function(t){return e.onLoadJson(t)}}))),i.a.createElement("div",{className:"menu-item mrt-toolbox-menu vertical"},i.a.createElement("div",{className:"menu-item mrt-toolbox-tool-icon"},i.a.createElement(G.a,{type:"appstore",theme:"outlined",style:{color:x()("purple").luminance(.4).hex()}})))),i.a.createElement("div",{className:"mrt-qrcode",style:{display:this.state.displayQRCode?"block":"none"}},i.a.createElement("canvas",{id:"mrt-share-qrcode-canvas"})),i.a.createElement(H,{id:"mrt-viewer",data:this.props.data,userEdits:this.userEdits,hideSubBranch:this.state.hideSubBranch,disableTextClusterSpan:this.state.disableTextClusterSpan,fontExtraSize:this.state.fontExtraSize,authors:this.props.authors}))}}]),t}(i.a.Component),Z=function(e){function t(e){var a;return Object(s.a)(this,t),(a=Object(l.a)(this,Object(d.a)(t).call(this,e))).state={data:h},a}return Object(p.a)(t,e),Object(c.a)(t,[{key:"render",value:function(){var e=this;return i.a.createElement("div",{className:"App"},i.a.createElement($,{data:this.state.data,authors:["Somefive","Rainatum"],onLoadJson:function(t){return e.setState({data:t})}}))}}]),t}(i.a.Component);Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));o.a.render(i.a.createElement(Z,null),document.getElementById("root")),"serviceWorker"in navigator&&navigator.serviceWorker.ready.then((function(e){e.unregister()}))}},[[163,1,2]]]);
//# sourceMappingURL=main.d9f21291.chunk.js.map